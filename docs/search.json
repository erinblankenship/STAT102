[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Stat 102 Notes",
    "section": "",
    "text": "Course Goals for STAT 102\nSTAT 212 is an introduction to the statistical aspects of study design. We’ll consider all stages of the experimental process. By the end of the course, you will:\n\nunderstand the differences between designed experiments and observational studies, including the resulting conclusions that can be drawn.\nbe familiar with major experimental and treatment design structures, and what to consider when choosing an appropriate design for a study.\nunderstand the impact of sample size, variation, and effect size on power.\nbe able to write down a linear additive model, correctly specify fixed effects, random effects, interactions, and model assumptions for the error terms.\nsketch a skeleton ANOVA table from a description of a study.\nunderstand data collection considerations\nbe able to analyze data resulting from major experimental and treatment design structures, including estimating main and simple effects, pairwise comparisons, contrasts, and model parameters.\nbe able to clearly write up the results of an analysis so that a non-statistician could understand the major findings of the study.",
    "crumbs": [
      "Course Goals for STAT 102"
    ]
  },
  {
    "objectID": "Section 1 Introduction.html",
    "href": "Section 1 Introduction.html",
    "title": "1  Introduction to Design",
    "section": "",
    "text": "In interpreting and in presenting experimental results there is no adequate substitute for thought–thought about the questions to be asked, thought about the nature and weight of evidence the data provide on those questions, and thought about how the story can be told with clarity and full honesty to a reader. Statistical techniques must be chosen and used to aid, but not to replace, relevant thought.\n- Bryan-Jones and Finney, 1983\n\nThere are two aspects to any design of experiments problem: the actual design and the analysis of the data from the experiment. We’ll be discussing both aspects at length is semester in about equal measure.\nExperimentation is one of the most common activities that people engage in, because it allows an investigator to find out what happens to a response when settings of another variable are purposefully changed. The results of the experiment provide a basis for selecting optimum settings or determine a plan of action. Experimentation is carried out by everyone, in everyday activities. For example, observing what happens to the taste of brownies if you change the material of the baking dish or the oven temperature. Changing the time you visit the dining hall to determine if it is less crowded. Changing a pet’s food to see if they eat better/more. All of these experiments.\nCan you think of others?\n\n\n\n\n\n\nThe goal of STAT 212 is to fully explore the “relevant thought” in the Bryan-Jones and Finney quote above, and to help you become independent in this thought. By the end of the semester you should be able to:\n\nOptimally design simple studies to answer a research question.\n\n\n\n\nCompute and interpret the analysis of data resulting from these designs.\n\n\n\n\nCommunicate the results of your analysis to non-statisticians both verbally and in writing.\n\n\n\n\nConverse intelligently about more complex designs with someone who has more training.\n\nWell-designed experiments allow an investigator to conduct better studies more efficiently, analyze data effectively, and make the connections between the conclusions from the analysis and the original research objectives. In every experiment, there are seven basic steps:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThroughout these steps, we must always keeps the following in mind:\n\n\n\n\n\n\n\n\n\n\nTo look at these in more detail, let’s consider an example (and state a few definitions along the way).\nExample: Two students at Queensland University of Technology, as a project for their statistics class, carried out an experiment to test the effect certain factors such as refrigeration, stem length, and water content have on the life of a cut rose. The students considered\n\nStem length (15 cm or 25 cm)\nWater content (tap water or tap water + citric acid)\nTemperature (refrigerated or room temperature)\n\nThe response measured was the number of days until death, and the goal is to determine the conditions that will extend rose life.\nIn this example, there are 3 factors.\nDefinition:\n\n\nIn order to study the effect of the factor on the response, two or more values of the factor are considered. These values are called levels.\n\n\n\n\nA treatment is a combination of factor levels. In this experiment:\n\nFactors:\n\n\n\n\nLevels:\n\n\n\n\n\n\nTreatments:\n\n\n\n\n\n\n\nDefinition: The treatment design\n\n\n\n\n\n\n\n\nDefinition: The experimental design\n\n\n\n\n\nThere are three main principles of experimental design that must be addressed with every design. They are:\n\nReplication:\n\n \n \n \n \n \nWhy it’s important:\n \n \n \n \n \n \nEach rose in the experiment above, each replicate, is an experimental unit. An experimental unit is the smallest physical entity to which a treatment can be INDEPENDENTLY applied.\nThe sampling unit is the entity that is actually observed or measured.\n \n \n \n \n \n \nPseudo-replication occurs when subsets of the experimental units (often sampling units) are mistakenly identified as experimental units. This is the most common serious design error.\nExamples:\n \n \n \n\nRandomization:\n\n\n\n\n\n\n\n\n\n\nWhy it’s important:\n\n\n\n\n\n\n\n\n3. Control/Blocking:\n\n\n\n\n\n\n\n\n\n\nWhy it’s important:\n\n\n\n\nTo make sure everyone’s on the same page, let’s review the two-sample case. Back to the example.\nExample: Let’s consider just the data on refrigeration vs room temperature. There were 16 roses: 8 stored at room temperature and 8 stored in a refrigerator. Let\n\n\\[\\mu_1 = \\hspace{80mm}\\]\n\\[\\mu_2 = \\hspace{80mm}\\]\n\nWe have observations \\[y_{ij} = \\hspace{80mm}\\]\nWe can express each observation as a combination of the treatment mean and the characteristics unique to each individual rose.\n\n\n\n\nIn STAT 102/318 we assume:\nWe can further decompose \\(\\mu_i\\):\n\n\n\n\n\n\n\n\n\n\nThe Central Limit Theorem says that the sample means \\(\\overline{y}_{i\\cdot}\\) will be (approximately) normally distributed with mean \\(\\mu_i\\) and variance \\(\\sigma^2/n\\). We also have to estimate \\(\\sigma^2\\), the variance of \\(e_{ij}\\) and hence the variance of \\(y_{ij}\\).\n\n\n\n\n\n\nTo determine if refrigeration and room temperature produce different lifetimes of cut roses we can test the null hypothesis H\\(_0: \\mu_1 = \\mu_2\\) or we can estimate \\(\\mu_1 - \\mu_2\\) with confidence using \\(t\\)-procedures.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe could also use the Analysis of Variance. The ANOVA table would look like:\n\n\n\n\nSource\ndf\nSum of Sq\nMean Sq\nF\np-value\n\n\n\n\nModel\n\nSSTrt\nMSTrt\nMSTrt/MSE\n\n\n\nError\n\nSSError\nMSE\n\n\n\n\nTotal\n\nSSTotal\n\n\n\n\n\n\n\nThere are two mistakes we could make carrying out this test.\n\nType I Error:\n\n\n\n\n\n\n\nType II Error:\n\n\n\n\n\nA new concept we’ll talk about this semester is closely related to Type II Error: power.\nDefinition: Power\n\n\n\n\n\n\nAll of these concepts of treatment design, experimental design, power, factors, and levels will be revisited many times over the course of the semester with increasingly complex treatment and experimental designs. We’ll start with the simplest experimental design: the Completely Randomized Design (CRD).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Design</span>"
    ]
  },
  {
    "objectID": "Section 2 Completely Randomized Design.html",
    "href": "Section 2 Completely Randomized Design.html",
    "title": "2  The Completely Randomized Design",
    "section": "",
    "text": "2.1 CRD Model and Basic Analysis\nThe first experimental design we’ll consider is the completely randomized design or CRD. The CRD is an experimental design because\nThe CRD is characterized by\nThe CRD may be combined with several different treatment designs. To explore the CRD in more detail, we’ll start with the simplest treatment design, the one-way design. The one-way design is so named because\nWithin one-way designs there are four basic treatment structures:\nExample: A donut manufacturer wants to see if the type of fat used to fry the donuts has any impact on the amount of fat absorbed by the donuts. The manufacturer has two types of animal fat and two types of vegetable fat that they would like to compare. They also have available 4 fryers, which can each fry 1 batch of 18 donuts at a time. They plan to measure the amount of fat absorbed in each batch.They have the resources to test 24 total batches of donuts.\nThere are two possible scenarios for the CRD. Discuss the pros and cons of each, and decide which one you would use and why.\nHere’s one possible experimental layout\nThe CRD Model can be written in two different ways.\nSome consequences of these assumptions:\nExpected value:\nDispersion:\nDistribution:\nFor this particular treatment design, there are several hypothesis tests that may be of interest. Write out in the symbols the null and alternative hypotheses for the following specified objectives. Reminder: Fats 1 and 2 are animal fats and Fats 3 and 4 are vegetable fats.\nLet’s try out using SAS. We’ll start by reading in the data.\nHere are the results of proc print:\nWe can read the data in other ways as well. We’ll see other data set options as we encounter different types of variables.\nLet’s start by plotting the data.\nThat’s not very pretty. Graphics are never going to be as pretty as they are in R, but we can do better.\nNow let’s construct the ANOVA table:\nUnder the null hypothesis, H\\(_0: \\mu_1 = \\mu_2 = \\mu_3 = \\mu_4\\), or equivalently H\\(_0: \\tau_i = 0\\) for all \\(i\\).\nSo, if the null hypothesis is true\nand \\(F\\) follows the \\(F\\) distribution with num\\(_{df} = t-1\\) and den\\(_{df}=t(n-1)\\).\nLet’s fit this model in SAS. There are a couple of different procedures (’proc’s) we can use to do so. We’ll start with proc glimmix. This gives a LOT of output.\nThere’s a lot of stuff here, but what’s missing?\nLet’s try proc mixed.\nOne more try:\nFinally!\nLet’s go back to the glimmix output and look more carefully at some components. The output below comes from the lsmeans type/cl; statement.\nNow let’s look at what’s provided by the lsmeans type/pdiff; statement.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Completely Randomized Design</span>"
    ]
  },
  {
    "objectID": "Section 2 Completely Randomized Design.html#crd-model-and-basic-analysis",
    "href": "Section 2 Completely Randomized Design.html#crd-model-and-basic-analysis",
    "title": "2  The Completely Randomized Design",
    "section": "",
    "text": "\\(y_{ij}\\) = amount of fat absorbed by the \\(j^{th}\\) batch of donuts prepared using the \\(i^{th}\\) fat\n\\(\\mu\\) = overall mean fat absorbed by a batch of donuts\n\\(\\tau_i\\) = treatment effect of fat \\(i\\) = additional amount of fat absorbed on average by batches prepared using fat type \\(i\\)\n\\(\\epsilon_{ij}\\) = random error = additional amount of fat absorbed by the \\(j^{th}\\) batch of donuts prepared using fat \\(i\\)\n\n\n\n\n\n\n\n\n\nAre there differences among the four fats with respect to the amount of fat absorbed?\n\n\n\nDo the vegetable fats differ from the animal fats in the amount of fat absorbed?\n\n\n\nAre there differences between the two animal fats? Are there differences between the two vegetable fats?\n\n\n\n\n\n\nSAS code for reading in the donut data set\n\n\n\n\n\n\nDonut data set\n\n\n\n\n    proc plot data=donut1; *specifying the data set I want to plot;\n      plot absorb*type; *y-axis*x-axis;\n    run;\n\n    proc gplot data=donut1;\n      plot absorb*type='dot'; *'dot' is the symbol I want to use;\n    run;\n\n\n\n\n\n\n\n\n\n\n\n\n\nSource of Variation\ndf\nSS\nMS\nExpected MS\nF\n\n\n\n\nFat Type\n\\(t-1=3\\)\nSSTrt\nMST\n\\(\\sigma^2 + \\frac{n}{t-1}\\sum_{i=1}^4 \\tau_i^2\\)\nMST/MSE\n\n\nError\n\\(t(n-1) = 20\\)\nSSError\nMSE\n\\(\\sigma^2\\)\n\n\n\nTotal\n\\(nt-1=23\\)\nSSTotal\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    proc glimmix data=donut1;\n      class type; *telling SAS that fat type is the treatment factor;\n      model absorb=type; *model response = treatment factor;\n      lsmeans type/pdiff cl; *let's add some fanciness;\n    run;\n\n               The GLIMMIX Procedure\n                Model Information\n                \n    Data Set                     WORK.DONUT1\n    Response Variable            absorb\n    Response Distribution        Gaussian\n    Link Function                Identity\n    Variance Function            Default\n    Variance Matrix              Diagonal\n    Estimation Technique         Restricted Maximum Likelihood\n    Degrees of Freedom Method    Residual\n    \n    \n         Class Level Information\n         \n        Class    Levels    Values\n        type          4    1 2 3 4\n    \n    Number of Observations Read          24\n    Number of Observations Used          24\n    \n                Dimensions\n    \n    Covariance Parameters          1\n    Columns in X                   5\n    Columns in Z                   0\n    Subjects (Blocks in V)         1\n    Max Obs per Subject           24\n    \n    \n          Optimization Information\n    \n    Optimization Technique    None\n    Parameters                5\n    Lower Boundaries          1\n    Upper Boundaries          0\n    Fixed Effects             Not Profiled\n    \n    \n             Fit Statistics\n    \n    -2 Res Log Likelihood         156.21\n    AIC  (smaller is better)      166.21\n    AICC (smaller is better)      170.49\n    BIC  (smaller is better)      171.19\n    CAIC (smaller is better)      176.19\n    HQIC (smaller is better)      167.18\n    Pearson Chi-Square           2018.00\n    Pearson Chi-Square / DF       100.90\n    \n              Type III Tests of Fixed Effects\n    \n                    Num      Den\n     Effect         DF       DF    F Value    Pr &gt; F\n    \n      type            3       20       5.41    0.0069\n\n    \n               type Least Squares Means\n    \n                         Standard\n    type    Estimate       Error       DF    t Value    Pr &gt; |t|     Alpha       Lower       Upper\n    \n    1         172.00      4.1008       20      41.94      &lt;.0001      0.05      163.45      180.55\n    2         185.00      4.1008       20      45.11      &lt;.0001      0.05      176.45      193.55\n    3         176.00      4.1008       20      42.92      &lt;.0001      0.05      167.45      184.55\n    4         162.00      4.1008       20      39.50      &lt;.0001      0.05      153.45      170.55\n    \n    \n            Differences of type Least Squares Means\n    \n                               Standard\n    type   _type   Estimate      Error      DF   t Value   Pr &gt; |t|    Alpha      Lower      Upper\n    \n    1      2       -13.0000     5.7994      20     -2.24     0.0365     0.05   -25.0974    -0.9026\n    1      3        -4.0000     5.7994      20     -0.69     0.4983     0.05   -16.0974     8.0974\n    1      4        10.0000     5.7994      20      1.72     0.1001     0.05    -2.0974    22.0974\n    2      3         9.0000     5.7994      20      1.55     0.1364     0.05    -3.0974    21.0974\n    2      4        23.0000     5.7994      20      3.97     0.0008     0.05    10.9026    35.0974\n    3      4        14.0000     5.7994      20      2.41     0.0255     0.05     1.9026    26.0974\n\n\n\n    proc mixed data=donut1;\n      class type;\n      model absorb=type;\n    run;\n\n    proc mixed data=donut1 method=type3;\n      class type;\n      model absorb=type;\n    run;\n\n                            Type 3 Analysis of Variance\n                        Sum of                                                             Error\nSource        DF       Squares   Mean Square  Expected Mean Square       Error Term           DF\ntype           3   1636.500000    545.500000  Var(Residual) + Q(type)    MS(Residual)         20\nResidual      20   2018.000000    100.900000  Var(Residual)              .                     .\n    \n    Type 3 Analysis of Variance\n    Source    F Value    Pr &gt; F\n    type         5.41    0.0069\n    Residual      .       .\n\n                                        type Least Squares Means\n                        Standard\n    type    Estimate       Error       DF    t Value    Pr &gt; |t|     Alpha       Lower       Upper\n    1         172.00      4.1008       20      41.94      &lt;.0001      0.05      163.45      180.55\n    2         185.00      4.1008       20      45.11      &lt;.0001      0.05      176.45      193.55\n    3         176.00      4.1008       20      42.92      &lt;.0001      0.05      167.45      184.55\n    4         162.00      4.1008       20      39.50      &lt;.0001      0.05      153.45      170.55\n    \n\n                                Differences of type Least Squares Means\n                                \n                              Standard\n    type   _type   Estimate      Error      DF   t Value   Pr &gt; |t|    Alpha      Lower      Upper\n    \n    1      2       -13.0000     5.7994      20     -2.24     0.0365     0.05   -25.0974    -0.9026\n    1      3        -4.0000     5.7994      20     -0.69     0.4983     0.05   -16.0974     8.0974\n    1      4        10.0000     5.7994      20      1.72     0.1001     0.05    -2.0974    22.0974\n    2      3         9.0000     5.7994      20      1.55     0.1364     0.05    -3.0974    21.0974\n    2      4        23.0000     5.7994      20      3.97     0.0008     0.05    10.9026    35.0974\n    3      4        14.0000     5.7994      20      2.41     0.0255     0.05     1.9026    26.0974",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Completely Randomized Design</span>"
    ]
  },
  {
    "objectID": "Section 2 Completely Randomized Design.html#treatment-comparisons-and-contrasts",
    "href": "Section 2 Completely Randomized Design.html#treatment-comparisons-and-contrasts",
    "title": "2  The Completely Randomized Design",
    "section": "2.2 Treatment Comparisons and Contrasts",
    "text": "2.2 Treatment Comparisons and Contrasts\nWe can see in the results above that we may reject the overall hypothesis that the four treatments produce the same mean fat absorption (\\(F=5.41\\), p-value\\(=0.0069\\)). But, this doesn’t address the hypotheses you constructed earlier. Remember, we also considered:\n\nDo the vegetable fats differ from the animal fats in the amount of fat absorbed?\nAre there differences between the two animal fats?\nAre there differences between the two vegetable fats?\n\nThe output above allows us to address some of these questions, but not the one regarding vegetable fats versus animal fats. Let’s look at a more general way to construct treatment comparisons.\nContrasts\nA well-thought-out treatment design’s objectives can usually be stated in terms of a set of contrasts. This is usually an important goal in planning the design, and contrasts are constructed before data are collected.\nA contrast is\n\n\n\n\n\n\nEstimates of the contrast are obtained by substituting in the sample means\n\n\n\n\n\nWe may also obtain standard errors of the contrast estimate\n\n\n\n\n\nStandard errors may then be used to carry out tests and construct confidence intervals.\n\n\n\n\n\n\n\nThe contrasts of interest depend on the basic treatment design structure and the goals of the experiment. Remember, the four basic structures are\n\nUnstructured\nControl versus other treatments\nQuantitative\nOther structure\n\nLet’s first consider Unstructured designs, because these are the simplest.\n\n2.2.1 Unstructured Treatment Designs and All Pairwise Comparisons\nExample: The New England Journal of Medicine published a study investigating the effects of different exercise programs on postural stability in Parkinson’s patients. The three exercise programs compared were: tai chi, resistance training, and stretching. 65 patients with Parkinson’s were randomly assigned to each program, and change in functional reach was measured after 24 weeks.\n\nTreatment Design:\n\nFactor:\nLevels:\n\nExperimental Design:\n\n\n\n\nIn designs like this without structure, we are typically interested in all pairwise comparisons.\n\n\n\n\n\n\n\nThere are multiple methods for making such comparisons. The simplest is the least significant difference (LSD), also called the unprotected LSD. It’s easy, but the Type I error rate can be badly inflated (we’ll talk more about this in a bit).\n\n\n\n\n\n\nA (slightly) more conservative option is Fisher’s protected LSD.\n\n\n\n\nWe’ve already seen these, but let’s add some fanciness!\n    proc glimmix data=reach;\n      class group;\n      model reach=group;\n      lsmeans group/pdiff cl lines plot=diffplot;\n    run;\nThis gives (in part) the output:\n             Type III Tests of Fixed Effects\n    \n                  Num      Den\n    Effect         DF       DF    F Value    Pr &gt; F\n    \n    Group           2      192      11.10    &lt;.0001\n    \n    \n                      Group Least Squares Means\n    \n                          Standard\n    Group      Estimate      Error      DF   t Value   Pr &gt; |t|    Alpha      Lower      Upper\n    \n    Resistan     2.3400     0.6130     192      3.82     0.0002     0.05     1.1310     3.5490\n    Stretchi     0.8569     0.6130     192      1.40     0.1637     0.05    -0.3521     2.0660\n    Tai_Chi      4.8938     0.6130     192      7.98     &lt;.0001     0.05     3.6848     6.1029\n    \n    \n                        Differences of Group Least Squares Means\n    \n                                  Standard\n    Group     _Group    Estimate     Error     DF  t Value  Pr &gt; |t|   Alpha     Lower     Upper\n    \n    Resistan  Stretchi    1.4831    0.8669    192     1.71    0.0887    0.05   -0.2268    3.1929\n    Resistan  Tai_Chi    -2.5538    0.8669    192    -2.95    0.0036    0.05   -4.2637   -0.8440\n    Stretchi  Tai_Chi    -4.0369    0.8669    192    -4.66    &lt;.0001    0.05   -5.7468   -2.3271\n    \n    \n    T Grouping for Group Least Squares Means (Alpha=0.05)\n    \n    LS-means with the same letter are not significantly different.\n    \n    Group       Estimate\n    \n    Tai_Chi       4.8938    A\n    \n    Resistan      2.3400    B\n                            B\n    Stretchi      0.8569    B\n    \n\n\n\nDiffogram for the reach data\n\n\nThis plot is called a diffogram and is a way to visualize differences among the treatments.\nSo these plots are awesome, and the output is easy to interpret! Why do we care about anything other than the LSD? The big issue is Type I error rate, and it can be a concern for pairwise comparisons as well as more complicated contrasts.\nMultiple Comparisons\nIf more than one comparison is made among the treatment means, then we have multiple comparisons which can lead to the problem of multiplicity.\nDefinition: Multiplicity is\n\n\n\n\nFor a single test, the significance level of a Type I error is called a comparison-wise error rate. This means\n\n\n\n\n\nBut, if we have multiple tests, the Type I errors for these tests accumulate. This accumulated rate is the called the experiment-wise error rate. This is\n\n\n\n\n\nBut, the errors don’t just add up. They accumulate in a power-type relationship. Consider a situation with a comparison-wise error rate of \\(\\alpha\\) and \\(c\\) independent comparisons. Then, the experiment-wise error rate is\n\n\n\n\n\nFor example, consider a situation with \\(\\alpha=0.05\\) and 5 independent comparisons (there are as many independent comparisons as there are \\(df\\) for treatment). In that case:\n\n\n\n\n\n\n\nWe can control the experiment-wise error rate by setting it to a pre-specified value \\(\\alpha\\) (maybe 0.05) and then solving for the comparison-wise error rate, assuming \\(c\\) independent comparisons. So, for example, if \\(\\alpha=0.05\\) and \\(c=5\\),\n\n\n\n\n\n\n\nWe’d then use this as the critical value (cut-off) value for our independent treatment comparisons.\nBut here’s another issue. If the comparisons are not independent (which they aren’t in all pairwise-comparisons, and often aren’t in pre-planned contrasts of interest), then the experiment-wise error rate is actually even bigger than we see above. What can we do?\nThere are a multitude of multiple comparison procedures which control the overall experiment-wise error rate, which have different pros and cons. We’re only going to the talk about a few.\nTukey’s HSD: Tukey’s Honestly Significant Difference (HSD) procedure is based on the studentized range statistic. To get this HSD from SAS:\n    proc glimmix data=reach;\n      class group;\n      model reach=group;\n      lsmeans group/pdiff cl adjust=tukey plot=diffplot;\n    run;\n\n                            Differences of Group Least Squares Means\n                            Adjustment for Multiple Comparisons: Tukey\n    \n                                    Standard\nGroup       _Group      Estimate       Error       DF    t Value    Pr &gt; |t|     Adj P     Alpha\n    \nResistan    Stretchi      1.4831      0.8669      192       1.71      0.0887    0.2038      0.05\nResistan    Tai_Chi      -2.5538      0.8669      192      -2.95      0.0036    0.0101      0.05\nStretchi    Tai_Chi      -4.0369      0.8669      192      -4.66      &lt;.0001    &lt;.0001      0.05\n    \n                   Differences of Group Least Squares Means\n                  Adjustment for Multiple Comparisons: Tukey\n    \n                                                        Adj         Adj\n    Group       _Group         Lower       Upper       Lower       Upper\n    \n    Resistan    Stretchi     -0.2268      3.1929     -0.5645      3.5307\n    Resistan    Tai_Chi      -4.2637     -0.8440     -4.6015     -0.5062\n    Stretchi    Tai_Chi      -5.7468     -2.3271     -6.0845     -1.9893\nThe diffogram is also adjusted.\nPros/Cons of the HSD:\n\n\n\n\n\nThe other multiple comparison procedures we’ll discuss are used with other treatment design structures. The three other one-way treatment design structures are:\n\nControl versus other treatments\nQuantitative (we’ll put a pin in this one for now)\nOther structure\n\n\n\n2.2.2 Control versus other treatments\nIn some scenarios, one of the factor levels acts as a control treatment for some or all of the remaining levels. Often, we are interested in comparing all of the treatments against the control but not against each other. This means there are\nDunnett’s procedures is a modification to the two-sample \\(t\\) test that is used when comparing all treatments against a control.\nExample: Sections of tomato plant tissue were grown in culture with differing amounts and types of sugars with five replications of four treatments. The treatments were: control, 3% glucose, 3% fructose, and 3% sucrose.\n\nTreatment Design:\n\nFactor:\nLevels:\n\nExperimental Design:\n\n\n\n\nIn a situation like this, we may be interested in comparing each of the sugar treatments to the control.\n    proc glimmix data=tomato;\n      class trt;\n      model growth=trt;\n      lsmeans trt/diff=control('control') cl adjust=dunnett plot=controlplot;\n    run;\n\n\nNote that unless otherwise specified, SAS will assume the first treatment level (alphabetically or numerically) is the control.\n                                    trt Least Squares Means\n                      Standard\ntrt        Estimate      Error      DF   t Value   Pr &gt; |t|    Alpha      Lower      Upper\ncontrol     42.2000     1.1726      16     35.99     &lt;.0001     0.05    39.7142    44.6858\nfructose    27.6000     1.1726      16     23.54     &lt;.0001     0.05    25.1142    30.0858\nglucose     29.0000     1.1726      16     24.73     &lt;.0001     0.05    26.5142    31.4858\nsucrose     34.0000     1.1726      16     29.00     &lt;.0001     0.05    31.5142    36.4858\n\n                            Differences of trt Least Squares Means\n                         Adjustment for Multiple Comparisons: Dunnett\n                                    Standard\ntrt         _trt        Estimate       Error       DF    t Value    Pr &gt; |t|     Adj P     Alpha\nfructose    control     -14.6000      1.6583       16      -8.80      &lt;.0001    &lt;.0001      0.05\nglucose     control     -13.2000      1.6583       16      -7.96      &lt;.0001    &lt;.0001      0.05\nsucrose     control      -8.2000      1.6583       16      -4.94      0.0001    0.0004      0.05\n\n                         Differences of trt Least Squares Means\n                     Adjustment for Multiple Comparisons: Dunnett\n                                                     Adj         Adj\ntrt         _trt           Lower       Upper       Lower       Upper\nfructose    control     -18.1155    -11.0845    -18.8990    -10.3010\nglucose     control     -16.7155     -9.6845    -17.4990     -8.9010\nsucrose     control     -11.7155     -4.6845    -12.4990     -3.9010\nWe get a new plot!\n\n\n\nControl plot for the tomato plant data\n\n\nPros/Cons of Dunnett’s Test:\n\n\n\n\n\n\n2.2.3 Treatment Designs with (other) Structure\nThis is where the donut example fits in. There isn’t a true control, but we also may not care about all pairwise comparisons. Instead, we had some specific, pre-planned comparisons of interest:\n\nDo the vegetable fats differ from the animal fats in the amount of fat absorbed?\nAre there differences between the two animal fats?\nAre there differences between the two vegetable fats?\n\nWhy pre-plan comparisons?\n\n\n\n\n\nEarlier, we wrote out the hypotheses of interest corresponding to these comparisons:\n\n\n\n\n\n\nThere are three options available in SAS to test these hypotheses and/or construct confidence intervals:\n\ncontrast statement\nestimate statement\nlsmestimate statement\n\nAll three statements involve specifying the coefficients of the treatment effects/treatment means. Let’s look at the comparison of vegetable and animal fats.\n\n \n\n\n\n\n\n\n\n\n\nand two different contrast statements we could write:\n    proc glimmix data=donut1;\n      class type;\n      model absorb=type;\n      contrast \"animal vs veg\" type 1 1 -1 -1;\n      contrast \"animal vs veg 2\" type 0.5 0.5 -0.5 -0.5;\n    run;\nBoth give the same results!\n                          Contrasts\n    \n    Num      Den\n    Label                DF       DF    F Value    Pr &gt; F\n    \n    animal vs veg         1       20       5.37    0.0313\n    animal vs veg 2       1       20       5.37    0.0313\n    \nLet’s try them with estimate statements, and add a third option:\n    estimate \"animal vs veg\" type 1 1 -1 -1;\n    estimate \"animal vs veg 2\" type 0.5 0.5 -0.5 -0.5;\n    estimate \"animal vs veg 3\" type 1 1 -1 -1/divisor=2;\n\n                                   Estimates\n    \n                                   Standard\n    Label              Estimate       Error       DF    t Value    Pr &gt; |t|\n    \n    animal vs veg       19.0000      8.2016       20       2.32      0.0313\n    animal vs veg 2      9.5000      4.1008       20       2.32      0.0313\n    animal vs veg 3      9.5000      4.1008       20       2.32      0.0313\n    \n                      type Least Squares Means\n    \n                        Standard\n    type    Estimate       Error       DF    t Value    Pr &gt; |t|\n    \n    1         172.00      4.1008       20      41.94      &lt;.0001\n    2         185.00      4.1008       20      45.11      &lt;.0001\n    3         176.00      4.1008       20      42.92      &lt;.0001\n    4         162.00      4.1008       20      39.50      &lt;.0001\n    \n    \nWhat’s going on?\n\n\n\n\n\n\n\n\n\nSuppose for some reason we wanted to test whether fats 1-3 (collectively) were different from fat 4.\n\n\n\n\n\n\n\nThe way we write the estimate statement really matters here:\n    estimate \"first 3 vs last\" type 0.33 0.33 0.33 -1;\n    estimate \"first 3 vs last\" type 1 1 1 -3/divisor=3;\n\n                                   Estimates\n    \n                                   Standard\n    Label              Estimate       Error       DF    t Value    Pr &gt; |t|\n    \n    first 3 vs last     Non-est           .        .        .         .\n    first 3 vs last     15.6667      4.7352       20       3.31      0.0035\nWe do still have a multiplicity issue, because we are interested in three pre-planned contrasts. We can use the Sidak adjustment to control experiment-wise error rate:\n    estimate \"1 vs 2\" type 1 -1 0 0,\n             \"3 vs 4\" type 0 0 1 -1,\n             \"animal vs veg\" type 0.5 0.5 -0.5 -0.5/adjust=sidak;\n                                  Estimates\n    \n                                   Standard\n    Label              Estimate       Error       DF    t Value    Pr &gt; |t|\n    \n    animal vs veg 2      9.5000      4.1008       20       2.32      0.0313\n    \n    \n\n                                  Estimates\n                        Adjustment for Multiplicity: Sidak\n    \n                                 Standard\n    Label            Estimate       Error       DF    t Value    Pr &gt; |t|     Adj P\n    \n    1 vs 2           -13.0000      5.7994       20      -2.24      0.0365    0.1055\n    3 vs 4            14.0000      5.7994       20       2.41      0.0255    0.0745\n    animal vs veg      9.5000      4.1008       20       2.32      0.0313    0.0909\n    \nFinally, we can use the lsmestimate statement. lsmestimate basically does the same thing as estimate but it allows for more complicated models than we have yet encountered. For a CRD, the output of the two should be identical, though lsmestimate does have some additional options (and slightly different syntax).\n    lsmestimate type \"1 vs 2\" 1 -1 0 0,\n                     \"3 vs 4\" 0 0 1 -1,\n                     \"animal vs veg\"  0.5 0.5 -0.5 -0.5/joint;\nThe joint option gives a joint test for whether the LSMeans are the same, which is the same as the overall test in the simple designs like the CRD. There are also multiple comparison adjustments available in lsmestimate.\nWhat happens if you don’t pre-plan? Ideally, comparisons are set up ahead of time based on specific research questions. If comparisons are selected after examining the data, most researchers construct tests that correspond to large differences in the means. These differences could be due to a real treatment effect, or they could be due to random error. Picking the largest differences to compare will inflate Type I error. If you do want to look at comparisons suggested by the data (post hoc comparisons), then you should replace the \\(t\\) test with a VERY conservative test called the Scheffé test. Scheffè works for pairwise comparisons or contrasts. We request it by adding the adjust=scheffe option.\nTo see how conservative Scheffè is, let’s look at the comparison of Fats 1 vs 2 (and pretend that Fat 1 is a control, just for illustration.\n\n\n\n\nAdjustment Type\np-value\nLower CL\nUpper CL\n\n\n\n\nUnadjusted\n0.0365\n-25.0974\n-0.9026\n\n\nTukey\n0.1462\n-29.2320\n3.2320\n\n\nDunnett\n0.0908\n-27.7326\n1.7326\n\n\nScheffè\n0.2044\n-30.6813\n4.6813\n\n\n\n\nWhat do you notice?\n\n\n\n\nWhich one to use? It depends. Is it more important to control the comparison-wise error rate or experiment-wise error rate? That will depend on the situation. Keep in mind that the more conservative the adjustment, the lower the power. That is, the more likely you are to make a Type II error.\nA Note on Independent Comparisons: As mentioned above, there can be as many independent comparisons as there are \\(df\\) for treatment. However, just because the number of planned comparisons equals the number of treatment \\(df\\) does not mean they are independent.\nIndependent contrasts are also called orthogonal contrasts. Orthogonality means that one contrast conveys no information about the other. We can check whether contrasts are orthogonal.\nDefinition: Two contrasts with coefficients \\(c_i\\) and \\(d_j\\) are orthogonal if\n\n\n\n\n\n\nLet’s consider the three contrasts in the donut example.\n\n\n\n\nPractice: Determine if the following set of contrasts for the donut example are orthogonal.\n\nH\\(_0: \\tau_1 - \\tau_2 = 0\\)\nH\\(_0: \\tau_1 - \\tau_3 = 0\\)\nH\\(_0: \\tau_1 - \\tau_4 = 0\\)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Completely Randomized Design</span>"
    ]
  },
  {
    "objectID": "Section 2 Completely Randomized Design.html#model-adequacy",
    "href": "Section 2 Completely Randomized Design.html#model-adequacy",
    "title": "2  The Completely Randomized Design",
    "section": "2.3 Model Adequacy",
    "text": "2.3 Model Adequacy\nEverything we’ve done so far is based on the assumptions that the observations are adequately described by the model\n\n\n\n\n\n\n\n\n\n\n\n\n\nIf these assumptions are not valid, then the estimates of the treatment means and tests of significance from the ANOVA will be affected. We typically use residuals as a basis of our diagnostic tools.\nThe residual for observation \\(j\\) in treatment \\(i\\) is defined as:\n\n\n\nExamining residuals should be an automatic part of the analysis of variance, and can be used to check the assumptions of common variance and normality of the error term. The assumptions can be checked using a visual inspection or formally through tests, and SAS makes it very easy to do so.\nThere’s a lot of code here, but we’ll examine it piece-by-piece.\n    proc glimmix data=donut1 plot=residualpanel;\n      class type;\n      model absorb=type; \n      random _residual_/group=type;\n      covtest homogeneity;\n      output out=donutout pred=pred residual=resid;\n    run;\nHere’s what the options are doing:\n\nplot=residualpanel produces a set of residual plots\nrandom _residual_/group=type tells SAS you want to estimate a residual variance for each treatment group (i.e., get separate estimates of \\(\\sigma^2\\) from each treatment group)\ncovtest produces a hypothesis test for comparing variances, and homogeneity says you want to test whether they are all equal\noutput produces a new data set (called donutout) which contains the observed residuals (resid) and predicted values (pred)\n\n\n\n\nResidual panel for the donut data\n\n\nThe upper left hand plot shows\n\n\nThe other three plots all deal with the normality assumption.\n\n\n\n\n\n\n\n\n\n\nWe can also use proc univariate to check normality, using the donoutout data set we created above.\n    proc univariate data=donutout plot normal;\n      var resid;\n    run;\nHere’s part of the output\n                           Tests for Normality\n    \n    Test                  --Statistic---    -----p Value------\n    \n    Shapiro-Wilk          W     0.972165    Pr &lt; W      0.7205\n    \nThe Shapiro-Wilk test is the most commonly used test for normality. A highly significant p-value would indicate there may be a problem with non-normality.\nWhat happens if we do see a large departure from normality?\n\n\n\n\n\nThe other assumption we can check with residuals is the constant variance assumption, also called the assumption of homogeneous variances. From the SAS output\n           Covariance Parameter Estimates\n                                           Standard\n    Cov Parm         Group     Estimate       Error\n    Residual (VC)    type 1      178.00      112.58\n    Residual (VC)    type 2     60.4000     38.2003\n    Residual (VC)    type 3     97.6000     61.7277\n    Residual (VC)    type 4     67.6000     42.7540\n    \n          Type III Tests of Fixed Effects\n                  Num      Den\n    Effect         DF       DF    F Value    Pr &gt; F\n    type            3       20       8.39    0.0008\n    \n               Tests of Covariance Parameters\n              Based on the Restricted Likelihood\n    Label            DF    -2 Res Log Like      ChiSq    Pr &gt; ChiSq    Note\n    Homogeneity       3             156.21       1.90        0.5942    DF\n    \n    DF: P-value based on a chi-square with DF degrees of freedom.\nThe covariance parameter estimates are the estimates of the variances for each of the four treatments, along with their standard errors. What do you notice?\n\n\n\n\n\nThe Tests of Covariance Parameters is testing the null hypothesis that the four variances are equal, versus the alternative that at least one is different.\n\n\n\n\n\nIn general, moderate departures from normality are of little concern, especially with the CRD. Nonconstant variance can be a bigger issue, but there are things we can do (like transformations) to stabilize the variance.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Completely Randomized Design</span>"
    ]
  },
  {
    "objectID": "Section 2 Completely Randomized Design.html#power-for-the-completely-randomized-design",
    "href": "Section 2 Completely Randomized Design.html#power-for-the-completely-randomized-design",
    "title": "2  The Completely Randomized Design",
    "section": "2.4 Power for the Completely Randomized Design",
    "text": "2.4 Power for the Completely Randomized Design\nWith multiple comparisons, we talked about Type I error and its probability. We defined Type I error as rejecting the null hypothesis when it is, in fact, true. If P(Type I error) = \\(\\alpha\\), then P(no Type I error) = \\(1-\\alpha\\).\nThere is another kind of error – Type II error. A Type II error occurs when H\\(_0\\) is not rejected, but H\\(_0\\) is actually false. In earlier courses, we summarized these two types of errors in a table:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEarlier in STAT 212, as well as other classes, we’ve said that we can “set” the probability of a Type I error. Anytime we say we’ll reject H\\(_0\\) if the p-value \\(&lt; \\alpha\\), we’re setting P(Type I error) = \\(\\alpha\\). What about Type II error? We generally call the probability of a Type II error \\(\\beta\\), P(Type II error) = \\(\\beta\\). The problem is we can’t “set” both \\(\\beta\\) and \\(\\alpha\\) without some other complications.\nWe are typically interested in the power of a test:\n\n\n\n\n\n\nLet’s explore this via simulation. Consider a two-sample \\(t\\)-test. In Canvas, there is an R file called simulation example.R.\n\nIn the program, we’re generating \\(n_1=20\\) normal random variables with \\(\\mu_1=10\\), \\(\\sigma^2=25\\) and \\(n_2=20\\) normal random variables with \\(\\mu_2=10\\), \\(\\sigma^2=25\\).\nCarry out the t-test (code already included) and observe the p-value. Using \\(\\alpha=0.10\\), what is your decision?\nRun the program 9 more times, so you have a total of 10 p-values. How many times out of 10 did you reject H\\(_0\\)?\nWhat does this estimate?\n\n\nEdit the program to generate data with \\(\\mu_1=10\\) and \\(\\mu_2=12\\) (still with \\(n_1=n_2=20\\) and \\(\\sigma^2=25\\)). Run the program 10 times total. How many times did you reject H\\(_0\\), using \\(\\alpha=0.10\\)?\nEdit the program to generate data with \\(\\mu_1=10\\) and \\(\\mu_2=15\\) (still with \\(n_1=n_2=20\\) and \\(\\sigma^2=25\\)). Run the program 10 times total. How many times did you reject H\\(_0\\), using \\(\\alpha=0.10\\)?\nEdit the program to generate data with \\(\\mu_1=10\\) and \\(\\mu_2=20\\) (still with \\(n_1=n_2=20\\) and \\(\\sigma^2=25\\)). Run the program 10 times total. How many times did you reject H\\(_0\\), using \\(\\alpha=0.10\\)?\n\nWhat do you observe as \\(\\mu_1\\) and \\(\\mu_2\\) get further apart?\n\n\n\n\n\nNow let’s try the following:\n\nEdit the program to generate data with \\(\\mu_1=10\\) and \\(\\mu_2=12\\), but with \\(\\sigma^2=1\\) (still with \\(n_1=n_2=20\\)). Run the program 10 times total. How many times did you reject H\\(_0\\), using \\(\\alpha=0.10\\)?\nEdit the program to generate data with \\(\\mu_1=10\\) and \\(\\mu_2=20\\), but with \\(\\sigma^2=625\\) (still with \\(n_1=n_2=20\\)). Run the program 10 times total. How many times did you reject H\\(_0\\), using \\(\\alpha=0.10\\)?\n\nWhat do observe as \\(\\sigma^2\\) gets larger or smaller?\n\n\n\n\n\nPower is the probability of rejecting H\\(_0\\) when it is really false. It is a function of several quantities:\n\n\n\n\n\n\n\n\n\n\nPower analyses usually focus on calculating the sample size required to achieve a particular power. What do you think would happen if instead of using \\(n_1=n_2=20\\) we used \\(n_1=n_2=10\\)?\n\n\nWhat do you think would happen if instead of using \\(n_1=n_2=20\\) we used \\(n_1=n_2=40\\)?\n\n\n\n\nWhat do you think would happen if instead of using \\(n_1=n_2=20\\) we used \\(n_1=10\\) and \\(n_2=30\\)?\n\n\n\n\nIn some simple situations, we can SAS procs to do power calculations. There are two: PROC POWER and PROC GLMPOWER. In some more complicated situations we’ll need to write our own code. We’ll start with PROC POWER. This proc will do power calculations for two sample \\(t\\) tests and ANOVA.\nFor a two-sample \\(t\\) test, the basic code is:\n        proc power;\n          twosamplemeans test=diff\n          alpha=\n          stddev=\n          meandiff=\n          npergroup=\n          power=               ;\n        run;\nWe’ll need to supply values for alpha, stddev, and meandiff. We can either supply a value for npergroup and use power=. or supply a value for power and use npergroup=.\nWe could also add the lines\n\nplot x=power min=0.5 max=0.95; (for ntotal=.)\nx=n min= max= ; (for power=.)\n\nLet’s try this, going back to our example with \\(\\mu_1=10\\), \\(\\mu_2=12\\), and \\(\\sigma^2=25\\).\n\n\n\n\nWe can also use PROC POWER for ANOVA and contrasts. This time, the basic code is:\n    proc power;\n      onewayanova\n      alpha=\n      stddev=\n      groupmeans=  |   |\n      ntotal=\n      power=\n      contrast= (     );\n    run;\nLet’s go back to the donut data. In that example, the MSE was 100.90, so we’ll use \\(\\sigma=10\\) as a guess for future experiments. We observed sample means of \\(\\overline y_{1\\cdot}=172\\), \\(\\overline y_{2\\cdot}=185\\), \\(\\overline y_{3\\cdot}=176\\), and \\(\\overline y_{4\\cdot}=162\\). We can certainly use these as guesses for future experiments. We’ll consider the contrast testing animal fats versus vegetable fats. We could also look at the overall test.\n\n\n\n\nWe can also add plot statements here.\n\n\n\n\nBut, we don’t actually have to have guesses for the treatment means. We do have to have an idea of how large a difference we want to be able to detect. With our example data, we had a animal fat mean of 178.5 and a vegetable fat mean of 169. This is a difference of 9.5.\n\n\n\n\nWe could also the consider potential differences we might observe in pairwise differences.\n\n\n\n\nThere are situations, however, where PROC POWER doesn’t work. It can’t handle more than one factor, a treatment design we’ll see in a couple of weeks. And, it can’t handle any model with a random effect other than \\(e_{ij}\\), a consequence of experimental designs we’ll see shortly.\nLet’s go back to the donut scenario. In that case, the ANOVA table was\n\n\n\n\n\n\n\n\n\n\n\n\nSource of Variation\ndf\nSS\nMS\nExpected MS\nF\n\n\n\n\nFat Type\n\\(t-1=4-1=3\\)\nSSTrt\nMST\n\\(\\sigma^2 + \\frac{n}{t-1}\\sum_{i=1}^4 \\tau_i^2\\)\nMST/MSE\n\n\nError\n\\(t(n-1) = 4(6-1) = 20\\)\nSSError\nMSE\n\\(\\sigma^2\\)\n\n\n\nTotal\n\\(nt-1=(4)(6)-1=23\\)\nSSTotal\n\n\n\n\n\n\n\nWhen we considered this ANOVA table back in Chapter 3, we observed\n\n\n\n\n\n\n\n\n\n\n\n\n\nBut, power is about detecting when the null hypothesis is NOT true. It turns out that if H\\(_0\\) is not true, the \\(F\\) ratio follows a different distribution:\n\n\n\n\n\n\n\n\n\n\nThe term SSHyp means\n\n\n\n\n\n\n\n\nWe can determine the power of an overall \\(F\\) test or contrast under a specified alternative by tricking PROC GLIMMIX into computing \\(\\lambda\\) and then using it to compute power. There are three basic steps.\n\nGenerate data set where all \\(y_{ij}\\) are set to the alternative value \\(\\mu_i\\) (the “true” \\(\\mu_i\\) MUST be specified by the researcher). A “true” value of \\(\\sigma^2\\) must also be specified.\n\n\n\nRun PROC GLIMMIX on these data, but fix \\(\\sigma^2\\) at the value specified by the researcher (don’t let SAS estimate it). Use GLIMMIX to calculate the overall \\(F\\) and \\(F\\) values for any contrasts. This means the contrast statement must be used, not estimate or lsmestimate. The product of the numerator degrees of freedom and the resulting overall ANOVA and contrast \\(F\\) values are the \\(\\lambda\\)s.\nUse the results from (2) in the SAS \\(F\\) probability functions to compute power.\n\nLet’s go back to the donuts.\n\nStep 1: Generate or simulate the data of “true” means.\n\n        data donutpower;\n          input trt mu;\n          do eu=1 to 6; *6 batches per treatment;\n            output;\n          end;\n        datalines;\n        1 172\n        2 185\n        3 176\n        4 162\n        ;   \n\nStep 2: Run GLIMMIX, fixing the true value of \\(\\sigma^2\\) at 100.\n\n            proc glimmix data=donutpower;\n              class trt;\n              model mu=trt;\n              parms (100)/hold=1;\n              contrast 'animal vs veg' trt 0.5 0.5 -0.5 -0.5;\n            ods output tests3=b;\n            ods output contrasts=c;\n            run;\n            \n            proc print data=b;\n            proc print data=c; run;\nThis produces the output\n\n\n\nThe results of Step 2 in the power calculation.\n\n\n\nStep 3: Use the results from GLIMMIX to find the power.\n\n         data powerval;\n          set b c;\n          do alpha=0.10, 0.05, 0.01;\n            lambda=numdf*fvalue;\n            fcrit=finv(1-alpha, numdf, dendf, 0);\n            power=1-probf(fcrit, numdf, dendf,lambda);\n            output;\n          end;\n        proc print; run;\nWhich gives\n\n\n\nThe results of Step 3 in the power calculation.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Completely Randomized Design</span>"
    ]
  },
  {
    "objectID": "Section 2 Completely Randomized Design.html#quantitative-levels-of-a-factor",
    "href": "Section 2 Completely Randomized Design.html#quantitative-levels-of-a-factor",
    "title": "2  The Completely Randomized Design",
    "section": "2.5 Quantitative Levels of a Factor",
    "text": "2.5 Quantitative Levels of a Factor\nAs a reminder, we’ve considered four basic treatment structures that may be used in a one-way treatment design:\n\nUnstructured\nControl versus other treatments\nQuantitative\nOther structure\n\nThe last of the four treatment structures we still need address is the quantitative factor. Up to now, we’ve only considered qualitative factors. A qualitative factor is\n\n\n\nWe’ve seen many of these examples:\n\n\n\n\n\nOn the other hand, a quantitative factor is\n\n\n\n\nWhen we look at the initial experimental design (how the treatments are assigned to experimental units) and analysis of a study, it doesn’t really matter whether our factor is quantitative or qualitative. The researcher wants to know whether the response differs based on the treatment levels.\nHowever, many studies that have a quantitative factor are conducted because\n\n\n\n\nThe general approach to fitting these models is regression analysis. The functional relationship between the quantitative factor and the response may be linear or non-linear, and a polynomial model is often used to describe the functional relationship. It is the simplest of the linear functions.\nThe general form of a polynomial model of \\(p\\) degrees is\n\n\n\n\n\n\nThe objective is to determine\n\n\n\n\n\n\n\n\n\n\nExample: A researcher is interested in studying the tensile strength of a new synthetic fiber to use in a cotton blend for shirts. The researcher knows the strength of material is affected by the percent (by weight) of cotton used in the blend and a range between 10 and 40% cotton is necessary to meet other characteristics criteria, like accepting a no-iron treatment. The researcher decides to test a range of percentages of cotton: 15, 20, 25, 30, and 35% and has the resources to test five samples at each level. The data are:\n\n\n\n\n\n\n\nObs\n\n\n\n\n\n\nCotton %\n1\n2\n3\n4\n5\n\n\n15\n7\n7\n15\n11\n9\n\n\n20\n12\n17\n12\n18\n18\n\n\n25\n15\n19\n19\n21\n19\n\n\n30\n19\n25\n22\n19\n23\n\n\n35\n7\n10\n11\n15\n11\n\n\n\n\n\nTreatment Design:\n\nFactor:\nLevels:\n\nExperimental Design:\n\n\n\n\nLet’s first look at a plot of the treatment means by treatment level. We’ll use this code:\n    proc glimmix data=cotton;\n      class percent; *treating percent as a qualitative var only to get the trt means;\n      model strength=percent;\n      lsmeans percent/plot=meanplot(join); *connect the dots;\n    run;\nThis produces the plot\n\n\n\nPlot of the lsmeans corresponding to the levels of percent cotton.\n\n\nAnytime we’re fitting a polynomial model, the number of degrees \\(p\\) that can be fit is\n\n\nand each degree corresponds to 1 treatment degree of freedom. If we fit all terms, we get a complete partition of the treatment effect into its one degree of freedom components.\nIn the case, the highest order model we can fit is\n\n\nFrom the plot, it appears\nThe first model we’ll try fitting is a quartic model:\n\n\n\n\nwhere\n\n\n\n\n\nThere are two models/methods for fitting the polynomial model:\n\ndirect regression\northogonal polynomials\n\nDirect regression\nThe direct regression approach considers the treatment/explanatory variable as a regression variable, not an ANOVA variable (though we know they’re really the same model at their core!). Because we are treating our explanatory varibale as a regression variable, it must not appear in the class statement. The following code fits a quartic model to the data:\nproc glimmix data=cotton;\n  model strength=percent percent*percent percent*percent*percent \n                 percent*percent*percent*percent/htype=1,3;\n/*alternate model statement */\n* model strength=percent|percent|percent|percent/htype=1,3;\nrun;\nA few notes:\n\nWe’re asking for both Type I and Type III tests.\n\n\n\n\n\n\n\nNote the alternate model statement.\n\n\n\n\nHere’s part of the output\n                    Type I Tests of Fixed Effects\n    \n                             Num      Den\n    Effect                    DF       DF    F Value    Pr &gt; F\n    \n    percent                    1       20       4.12    0.0559\n    percent*percent            1       20      47.66    &lt;.0001\n    percen*percen*percen       1       20       7.96    0.0105\n    perc*perc*perc*perce       1       20       2.19    0.1549\n    \n    \n                   Type III Tests of Fixed Effects\n    \n                             Num      Den\n    Effect                    DF       DF    F Value    Pr &gt; F\n    \n    percent                    1       20       1.57    0.2242\n    percent*percent            1       20       1.67    0.2115\n    percen*percen*percen       1       20       1.88    0.1857\n    perc*perc*perc*perce       1       20       2.19    0.1549\n    \nThe Type I Tests\n\n\n\n\n\n\n\n\n\n\n\nSo, it looks like\n\n\n\n\nThe Type III Tests\n\n\n\n\n\n\n\n\nSo now we can rerun the analyses, keeping the terms up to the highest order that has a significant contribution. In our example\n\n\n\nWe’ll use the code:\n    proc glimmix data=cotton;\n      model strengt=percent|percent|percent/solution htype=1;\n    run;\nNote we’ve added the solution option, which will provide the parameter estimates for the effects. Here’s the output:\n                                 Parameter Estimates\n    \n                                        Standard\n    Effect                  Estimate       Error       DF    t Value    Pr &gt; |t|\n    \n    Intercept                59.5257     38.2927       21       1.55      0.1350\n    percent                  -8.7257      5.0052       21      -1.74      0.0959\n    percent*percent           0.4757      0.2081       21       2.29      0.0327\n    percen*percen*percen    -0.00760    0.002768       21      -2.75      0.0121\n    Scale                     8.6205      2.6604        .        .         .\n    \n    \n                                Type I Tests of Fixed Effects\n    \n                             Num      Den\n    Effect                    DF       DF    F Value    Pr &gt; F\n    \n    percent                    1       21       3.90    0.0616\n    percent*percent            1       21      45.12    &lt;.0001\n    percen*percen*percen       1       21       7.54    0.0121\n    \nWe can use these estimates to construct the fitted model:\n\n\n\n\n\n\nWe can also plot the predicted values from our equation\n    proc glimmix data=cotton;\n      model strength=percent|percent|percent/solution htype=1;\n      output out=cottonout pred=predicted;\n    run;\n    \n    proc print data=cottonout; run;\nWhich gives us the output data set that I’ve called cottonout:\n    Obs    percent    strength    predicted\n    \n     1       15          7        10.0257\n     2       15          7        10.0257\n     3       15         15        10.0257\n     4       15         11        10.0257\n     5       15          9        10.0257\n     6       20         12        14.4971\n     7       20         17        14.4971\n     8       20         12        14.4971\n     9       20         18        14.4971\n    10       20         18        14.4971\n    11       25         15        19.9543\n    12       25         19        19.9543\n    13       25         19        19.9543\n    14       25         21        19.9543\n    15       25         19        19.9543\n    16       30         19        20.6971\n    17       30         25        20.6971\n    18       30         22        20.6971\n    19       30         19        20.6971\n    20       30         23        20.6971\n    21       35          7        11.0257\n    22       35         10        11.0257\n    23       35         11        11.0257\n    24       35         15        11.0257\n    25       35         11        11.0257\n    \nTo plot the predicted values there are few options\n    title \"Regression model for cotton data\";\n    symbol1 interpol=none value=dot color=black;\n    symbol2 interpol=join value=diamond color=red;\n    proc gplot data=cottonout;\n      plot strength*percent predicted*percent/overlay;\n    run;\n    \n    title \"Regression model for cotton data\";\n    symbol1 interpol=none value=dot color=black;\n    symbol2 interpol=RC value=diamond color=red; *can only go up to a cubic;\n    proc gplot data=cottonout;\n      plot strength*percent predicted*percent/overlay;\n    run;\n    \n    title \"Regression model for cotton data\";\n    symbol1 interpol=none value=dot color=black;\n    symbol2 interpol=spline value=diamond color=red; \n    proc gplot data=cottonout;\n      plot strength*percent predicted*percent/overlay;\n    run;\nLet’s go to SAS to see the differences among these three plots.\nNotice that at the percents outside the inference space we get nonsense strength values. Only values between 15 and 35 percent are within the inference space.\nOrthogonal polynomials\nQuantitative factors levels are one of the few cases where a full set of orthogonal contrasts can be useful. However, this approach does require\n\n\n\nand involves testing orthogonal contrasts among the treatment factor levels. These contrasts allow us to evaluate the importance of each polynomial component with a specific contrast.\nHere are the steps:\n\n\n\n\n\n\n\n\n\n\n\n\nThe coefficients for polynomial contrasts are not obvious. It’s easiest to look them up (google orthogonal polynomial coefficients table). For a design with 5 equally spaced levels:\n\n\n\nOrthogonal polynomial coefficients for 5 equally spaced levels.\n\n\nSo, our code would look like:\n    proc glimmix data=cotton;\n      class percent;\n      model strength=percent;\n      contrast 'linear' percent -2 -1 0 1 2;\n      contrast 'quadratic' percent 2 -1 -2 -1 2;\n      contrast 'cubic' percent -1 2 0 -2 1;\n      contrast 'quartic' percent 1 -4 6 -4 1;\n    run;\nWhich gives the output:\n       Type III Tests of Fixed Effects\n\n              Num      Den\nEffect         DF       DF    F Value    Pr &gt; F\n\npercent         4       20      15.48    &lt;.0001\n\n\n                  Contrasts\n\n               Num      Den\nLabel          DF       DF    F Value    Pr &gt; F\n\nlinear          1       20       4.12    0.0559\nquadratic       1       20      47.66    &lt;.0001\ncubic           1       20       7.96    0.0105\nquartic         1       20       2.19    0.1549\nNote that these results are the same as we got with the direct regression method!",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Completely Randomized Design</span>"
    ]
  },
  {
    "objectID": "Section 3 Factorial Treatment Design.html",
    "href": "Section 3 Factorial Treatment Design.html",
    "title": "3  Factorial Treatment Designs",
    "section": "",
    "text": "3.1 Introduction and Model\nOften we are interested in more than one treatment factor. For example, we may want to look at\nA factorial arrangement of treatments is a treatment design that is the most efficient approach for this type of experiment. For example, we’ve already seen\nThe goal is to describe as simply as possible how these factors affect our response variable.\nWhy use Factorials?\nWe could investigate a single factor as a time:\nAlternatively, we could investigate every possible combination in a single experiment:\nWe’ll start by looking at the general set-up for a 2-factor design. Designate one factor as Factor A. Factor A has \\(a\\) levels. Designate the other factor as Factor B. Factor B has \\(b\\) levels. This means there are a total of \\(a \\times b\\) treatment combinations. We will still be thinking about this factorial treatment design in the context of the CRD experimental design.\nExample: In lab, you explored some data resulting from an experiment designed to study the effects of four treatments on the inches of fabric burned after a flame test. In the lab problem you were told\nSo really, rather than 1 factor (Treatment) with 4 levels, we have\nLet’s plot the data. Does it look like there is a difference among the treatments? Can we (easily) see if there are differences among different levels of the two factors?\nYour group was asked to come up with two contrasts. What contrasts did you use?\nIf we treat this experiment as the factorial treatment design that it is, we can look at the factors individually and in combination. We’ll need to start by adjusting the model and our notation.\nThe treatment combinations and their means can be summarized in a table\nThese are fixed, unknown values. The observed treatment means and marginal means are:\nWith a single factor, we could write the model in one of two ways:\nWith two factors, we can still write the model in one of two ways:\nBefore we can see how this new model gets translated into an ANOVA table, we need to explore the effect of a factor.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Factorial Treatment Designs</span>"
    ]
  },
  {
    "objectID": "Section 3 Factorial Treatment Design.html#introduction-and-model",
    "href": "Section 3 Factorial Treatment Design.html#introduction-and-model",
    "title": "3  Factorial Treatment Designs",
    "section": "",
    "text": "Treatment A = Cotton fabric, fire-retardant additive X\nTreatment B = Polyester fabric, fire-retardant additive X\nTreatment C = Cotton fabric, fire-retardant additive Y\nTreatment D = Polyester fabric, fire-retardant additive Y\n\n\n\n\n\n\n\n\n\n\nTreatment Combinations and Means\n\n\n\n\nFabric\n\n\n\n\n\nAdditive\n\nCotton\nPolyester\n\n\n\nX\n\n\n\n\n\nY\n\n\n\n\n\n\n\nObserved Cell and Marginal Means\n\n\n\n\nFabric\n\n\n\n\n\n\nAdditive\n\nCotton\nPolyester\nAdditive Means\n\n\n\nX\n\n\n\n\n\n\nY\n\n\n\n\n\nFabric Means",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Factorial Treatment Designs</span>"
    ]
  },
  {
    "objectID": "Section 3 Factorial Treatment Design.html#effects",
    "href": "Section 3 Factorial Treatment Design.html#effects",
    "title": "3  Factorial Treatment Designs",
    "section": "3.2 Effects",
    "text": "3.2 Effects\nDefinition: The effect of a factor\n\n\n\n\n\nThere are three types of effects in a factorial experiment:\n\n\n\n\n\n\n\nTo demonstrate these effects, we’ll go back to the pajamas example.\n\n3.2.1 Simple Effects\nSimple effects give the effect of one factor when the other(s) is held constant. So, a simple effect is the difference between two levels of a factor at a given level of the remaining factor(s).\nIn our pajama example there are 4 simple effects:\n\nThe simple effects comparing Cotton to Polyester:\n\ngiven Additive X\ngiven Additive Y\n\nThe simple effects comparing Additive X to Additive Y:\n\ngiven Cotton fabric\ngiven Polyester fabric\n\n\nWe can estimate the simple effects using our observed treatment means:\n\nThe estimated simple effects comparing Cotton to Polyester:\n\ngiven Additive X\ngiven Additive Y\n\nThe estimated simple effects comparing Additive X to Additive Y:\n\ngiven Cotton fabric\ngiven Polyester fabric\n\n\n\n\n3.2.2 Main Effects\nMain effects are averages of simple effects. Main effects average over a variety of conditions.\nIn our pajama example there are two main effects:\n\nMain effect for Fabric type:\n\n\n\n\n\n\n\n\nMain effect for Additive:\n\n\n\n\n\n\n\nMain effects can also be thought of as differences between marginal means for a given factor. Let’s look more closely at Fabric type effect:\n\n\n\n\n\n\n\n\n\n\n\nWe could also re-write the main effect for Additive in a similar way.\n\n\n\n\n\n\n\n\n\n3.2.3 Interaction Effects\nInteraction Effects are differences of simple effects, and interaction effects ask the question:\n\n\n\n\n\nWe do this by looking at the difference in the simple effects for one factor at two different levels of the second factor.\nFor example,\n\nThe simple effect of Fabric given Additive X\nThe simple effect of Fabric given Additive Y\n\nIs the effect of Fabric the same for both Additives?\n\n\n\n\n\n\n\n\n\n\n\n\nWhat about the effect of Additive for both Fabrics?\n\n\n\n\n\n\n\nPresence or absence of interaction effects can be illustrated graphically. We plot the response mean against one of the factors for both levels of the other factor. If the lines are approximately parallel, there is no interaction. If the lines are not parallel, there is interaction.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant Note: The presence or absence of main effects tells us NOTHING about the presence or absence of interaction.The presence or absence of interaction tells us NOTHING about the presence or absence of main effects. The presence of interaction DOES tell us something about the homogeneity of simple effects. When factors interact, a single factor experiment will lead to disconnected and possibly misleading results.\nWhy do we care?\nOne thing we noted at the beginning of this section\n\n\n\n\nThe presence or absence of interaction helps inform how we can best report the findings of the experiment.\n\nInteraction is non-significant:\n\n\n\n\n\n\nInteraction is significant\n\n\n\n\n\n\n\n\n\n\n\n\nIt’s never wrong to report simple effects,\n \n\nHow do we determine significant? That brings us to . . .",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Factorial Treatment Designs</span>"
    ]
  },
  {
    "objectID": "Section 3 Factorial Treatment Design.html#model-and-analysis",
    "href": "Section 3 Factorial Treatment Design.html#model-and-analysis",
    "title": "3  Factorial Treatment Designs",
    "section": "3.3 Model and Analysis",
    "text": "3.3 Model and Analysis\nWe’ll start with the simplest type of factorial design with 2 factors. As we mentioned earlier, we’ll assume \\(a\\) levels of Factor A and \\(b\\) levels of Factor B arranged in a . That is, each replication of the experiment contains all \\(a \\times b\\) treatment combinations. In general, there are \\(n\\) replicates. We call this a\n\n\nRecall that \\(y_{ijk}\\) represents\n\n\n\nIn general (assuming equal sample sizes, which is not necessary), the data can be represented as\n\n\n\n\n\n\nWe’ve been assuming that \\(\\mu_{ij}\\) represents the true mean for cell \\((i,j)\\). This implies the model\n\n\n\n\nThis is the cell means model. Like the the one-factor model, we can also write this using a treatment effects model:\n\n\n\n\n\n\n\n\n\n\n\n\n\nJust as our model grows bigger, so does our ANOVA table:\n\n\n\n\n\n\n\n\n\n\nWe can formally test for interaction by testing the hypotheses\n\n\n\n\nIf there is no interaction, we look at main effects. For the main effects we can test hypotheses about the equality of Factor A treatment effects:\n\n\n\n\nand the equality of Factor B effects:\n\n\n\n\nand the main effects can be used to summarize the experiment.\nIf interaction is present, we must summarize the experiment using simple effects. Main effects would not adequately represent the effect of the factors.\n Back to the pajamas data. We had two factors each with two levels, and 4 observations at each treatment combination. The linear model would be\n\n\n\n\n\n\n\nLet’s sketch the ANOVA table:\n\n\n\n\n\n\n\n\n\n\nFrom the interaction plot we saw earlier, it was unclear whether interaction is present or not. We can fit the ANOVA model using the code:\n  proc glimmix data=pajamas;\n     class fabric additive;\n       model burn=fabric additive fabric*additive;\n    run;\nAnd here is the output:\n                Fit Statistics\n    \n    -2 Res Log Likelihood          67.28\n    AIC  (smaller is better)       77.28\n    AICC (smaller is better)       87.28\n    BIC  (smaller is better)       79.71\n    CAIC (smaller is better)       84.71\n    HQIC (smaller is better)       76.38\n    Pearson Chi-Square            120.50\n    Pearson Chi-Square / DF        10.04\n    \n    \n               Type III Tests of Fixed Effects\n    \n                        Num      Den\n    Effect               DF       DF    F Value    Pr &gt; F\n    \n    fabric                1       12       4.88    0.0474\n    additive              1       12      75.31    &lt;.0001\n    fabric*additive       1       12       4.21    0.0627\nWhat do you think?\nWe can output the estimated effects and get a plot using\n    lsmeans fabric*additive/diff plot=diffplot;\nwhich gives\n                           fabric*additive Least Squares Means\n    \n                                       Standard\n    fabric    additive    Estimate       Error       DF    t Value    Pr &gt; |t|\n    \n    C         X            40.5000      1.5844       12      25.56      &lt;.0001\n    C         Y            30.0000      1.5844       12      18.93      &lt;.0001\n    P         X            47.2500      1.5844       12      29.82      &lt;.0001\n    P         Y            30.2500      1.5844       12      19.09      &lt;.0001\n    \n    \n                    Differences of fabric*additive Least Squares Means\n    \n                                                         Standard\n    fabric   additive   _fabric   _additive   Estimate      Error      DF   t Value   Pr &gt; |t|\n    \n    C        X          C         Y            10.5000     2.2407      12      4.69     0.0005\n    C        X          P         X            -6.7500     2.2407      12     -3.01     0.0108\n    C        X          P         Y            10.2500     2.2407      12      4.57     0.0006\n    C        Y          P         X           -17.2500     2.2407      12     -7.70     &lt;.0001\n    C        Y          P         Y            -0.2500     2.2407      12     -0.11     0.9130\n    P        X          P         Y            17.0000     2.2407      12      7.59     &lt;.0001\n\n\n\nDiffogram for pajama lsmeans\n\n\nWhat does this plot show us?\n\n\n\n\n\n\n\nAlthough we generally worry about testing the interaction effect, there may be times where we want to estimate the interaction. That is, we may be interested in the magnitude of the difference between the simple effects. We can do this by adding an estimate statement to the PROC GLIMMIX program:\n    estimate 'fabric x additive' fabric*additive 1 -1 -1 1/alpha=0.1;\nThis gives the output\n                                          Estimates\n        \n                                 Standard\nLabel              Estimate     Error     DF  t Value  Pr &gt; |t|   Alpha     Lower     Upper\n        \nfabric x additive   -6.5000    3.1689     12    -2.05    0.0627     0.1  -12.1478   -0.8522\n\n\n\n\nPROC GLIMMIX has both slice and slicediff options available that allow us to test one factor at each level of the other. The slice option is similar to a contrast statement, in that it only gives us the \\(F\\) stats and p-values. The slicediff option allows us to construct confidence intervals. Let’s see what they provide:\nslice option:\n     lsmeans fabric*additive/slice=fabric slice=additive;\n     Tests of Effect Slices for fabric*additive\n                 Sliced By fabric\n    \n                Num      Den\n    fabric      DF       DF    F Value    Pr &gt; F\n    \n    C            1       12      21.96    0.0005\n    P            1       12      57.56    &lt;.0001\n    \n    \n    Tests of Effect Slices for fabric*additive\n                  Sliced By additive\n    \n                  Num      Den\n    additive      DF       DF    F Value    Pr &gt; F\n    \n    X              1       12       9.07    0.0108\n    Y              1       12       0.01    0.9130\nslicediff option:\n     lsmeans fabric*additive/slicediff=fabric slicediff=additive cl;\n                                fabric*additive Least Squares Means\n                                Standard\nfabric  additive  Estimate     Error     DF  t Value  Pr &gt; |t|   Alpha     Lower     Upper\nC       X          40.5000    1.5844     12    25.56    &lt;.0001    0.05   37.0478   43.9522\nC       Y          30.0000    1.5844     12    18.93    &lt;.0001    0.05   26.5478   33.4522\nP       X          47.2500    1.5844     12    29.82    &lt;.0001    0.05   43.7978   50.7022\nP       Y          30.2500    1.5844     12    19.09    &lt;.0001    0.05   26.7978   33.7022\n        \n              Simple Effect Comparisons of fabric*additive Least Squares Means By fabric\nSimple\nEffect                                       Standard\nLevel      additive   _additive   Estimate      Error      DF   t Value   Pr &gt; |t|    Alpha\nfabric C   X          Y            10.5000     2.2407      12      4.69     0.0005     0.05\nfabric P   X          Y            17.0000     2.2407      12      7.59     &lt;.0001     0.05\n        \n              Simple Effect Comparisons of fabric*additive Least Squares Means By fabric\nSimple\nEffect\nLevel      additive   _additive      Lower       Upper\nfabric C   X          Y             5.6179     15.3821\nfabric P   X          Y            12.1179     21.8821\n        \n              Simple Effect Comparisons of fabric*additive Least Squares Means By additive\nSimple\nEffect                                         Standard\nLevel         fabric    _fabric    Estimate       Error       DF    t Value    Pr &gt; |t|     Alpha\nadditive X    C         P           -6.7500      2.2407       12      -3.01      0.0108      0.05\nadditive Y    C         P           -0.2500      2.2407       12      -0.11      0.9130      0.05\n        \n              Simple Effect Comparisons of fabric*additive Least Squares Means By additive\nSimple\nEffect\nLevel         fabric    _fabric       Lower       Upper\nadditive X    C         P          -11.6321     -1.8679\nadditive Y    C         P           -5.1321      4.6321\nWe may also construct confidence intervals for the marginal and cell means in a factorial experiment. To do this, we need the standard error of those means.\n\nMarginal mean of Factor A\n\n\n\n\n\n\n\nMarginal mean of Factor B\n\n\n\n\n\n\n\nCell means\n\n\n\n\n\n\nSo, a confidence interval for\n\nMarginal mean\n\n\n\n\n\n\n\n\n\n\nCell mean\n\n\n\n\nWe could also get a confidence interval for an interaction effect. Recall that an interaction effect for a 2 \\(\\times\\) 2 factorial is a contrast with the coeefficients 1 -1 -1 1. The standard error for a contrast is\n\n\n\n\nSo for the pajamas example, the standard error would be\n\n\n\n\nwhich would give a confidence interval\n\n\n\n\n\nUsing our pajamas example, we’ll use the following SAS program to see how to calculate estimates of the main effects, simple effects, and interaction effects to compare with what we did by hand.\nproc glimmix data=pajamas;\n    class fabric additive;\n    model burn=fabric additive fabric*additive;\n    lsmeans fabric additive fabric*additive/diff cl;\n    estimate 'main effect cotton fabric' intercept 2 fabric 2 0 additive 1 1 \n                fabric*additive 1 1 0 0/divisor=2 cl;\n    estimate 'main effect polyester fabric' intercept 2 fabric 0 2 additive 1 1 \n                fabric*additive 0 0 1 1/divisor=2 cl;\n    estimate 'main effect additive X' intercept 2 additive 2 0 fabric 1 1 \n                fabric*additive 1 0 1 0/divisor=2 cl;\n    estimate 'main effect additive Y' intercept 2 additive 0 2 fabric 1 1 \n                fabric*additive 0 1 0 1/divisor=2 cl;\n    estimate 'effect of fabric with add X' fabric 1 -1 fabric*additive 1 0 -1 0/cl;\n    estimate 'effect of fabric with add Y' fabric 1 -1 fabric*additive 0 1 0 -1/cl;\n    estimate 'effect of additive in cotton' additive 1 -1 fabric*additive 1 -1 0 0/cl;\n    estimate 'effect of additive in polyester' additive 1 -1 fabric*additive 0 0 1 -1/cl;\n    estimate 'fabric x additive' fabric*additive 1 -1 -1 1/cl;\n    contrast 'fabric with add X' fabric 1 -1 fabric*additive 1 0 -1 0;\n    contrast 'fabric with add Y' fabric 1 -1 fabric*additive 0 1 0 -1;\n    contrast 'additive in cotton' additive 1 -1 fabric*additive 1 -1 0 0;\n    contrast 'additive in polyester' additive 1 -1 fabric*additive 0 0 1 -1;\n    contrast 'interaction' fabric*additive 1 -1 -1 1;\nrun;\n                                            Estimates\n    \n                                                 Standard\nLabel                              Estimate       Error       DF    t Value    Pr &gt; |t|     Alpha\n    \nmain effect cotton fabric           35.2500      1.1204       12      31.46      &lt;.0001      0.05\nmain effect polyester fabric        38.7500      1.1204       12      34.59      &lt;.0001      0.05\nmain effect additive X              43.8750      1.1204       12      39.16      &lt;.0001      0.05\nmain effect additive Y              30.1250      1.1204       12      26.89      &lt;.0001      0.05\neffect of fabric with add X         -6.7500      2.2407       12      -3.01      0.0108      0.05\neffect of fabric with add Y         -0.2500      2.2407       12      -0.11      0.9130      0.05\neffect of additive in cotton        10.5000      2.2407       12       4.69      0.0005      0.05\neffect of additive in polyester     17.0000      2.2407       12       7.59      &lt;.0001      0.05\nfabric x additive                   -6.5000      3.1689       12      -2.05      0.0627      0.05\n    \n                        Estimates\n    \nLabel                                 Lower       Upper\n    \nmain effect cotton fabric           32.8089     37.6911\nmain effect polyester fabric        36.3089     41.1911\nmain effect additive X              41.4339     46.3161\nmain effect additive Y              27.6839     32.5661\neffect of fabric with add X        -11.6321     -1.8679\neffect of fabric with add Y         -5.1321      4.6321\neffect of additive in cotton         5.6179     15.3821\neffect of additive in polyester     12.1179     21.8821\nfabric x additive                  -13.4044      0.4044\n    \n                       Contrasts\n    \n                            Num      Den\nLabel                      DF       DF    F Value    Pr &gt; F\n    \nfabric with add X           1       12       9.07    0.0108\nfabric with add Y           1       12       0.01    0.9130\nadditive in cotton          1       12      21.96    0.0005\nadditive in polyester       1       12      57.56    &lt;.0001\ninteraction                 1       12       4.21    0.0627\n    \n                            fabric Least Squares Means\n\n                       Standard\nfabric    Estimate       Error       DF    t Value    Pr &gt; |t|     Alpha       Lower       Upper\n\nC          35.2500      1.1204       12      31.46      &lt;.0001      0.05     32.8089     37.6911\nP          38.7500      1.1204       12      34.59      &lt;.0001      0.05     36.3089     41.1911\n\n\n                     Differences of fabric Least Squares Means\n\n                            Standard\nfabric  _fabric  Estimate     Error     DF  t Value  Pr &gt; |t|   Alpha     Lower     Upper\n\nC       P         -3.5000    1.5844     12    -2.21    0.0474    0.05   -6.9522  -0.04782\n\n\n                           additive Least Squares Means\n\n                       Standard\nadditive   Estimate      Error      DF   t Value   Pr &gt; |t|    Alpha      Lower      Upper\n\nX           43.8750     1.1204      12     39.16     &lt;.0001     0.05    41.4339    46.3161\nY           30.1250     1.1204      12     26.89     &lt;.0001     0.05    27.6839    32.5661\n\n\n                    Differences of additive Least Squares Means\n\n                               Standard\nadditive  _additive  Estimate     Error     DF  t Value  Pr &gt; |t|   Alpha     Lower     Upper\n\nX         Y           13.7500    1.5844     12     8.68    &lt;.0001    0.05   10.2978   17.2022\n    \n    \n                          fabric*additive Least Squares Means\n\n                            Standard\nfabric  additive  Estimate     Error     DF  t Value  Pr &gt; |t|   Alpha     Lower     Upper\n\nC       X          40.5000    1.5844     12    25.56    &lt;.0001    0.05   37.0478   43.9522\nC       Y          30.0000    1.5844     12    18.93    &lt;.0001    0.05   26.5478   33.4522\nP       X          47.2500    1.5844     12    29.82    &lt;.0001    0.05   43.7978   50.7022\nP       Y          30.2500    1.5844     12    19.09    &lt;.0001    0.05   26.7978   33.7022\n\n\n                      Differences of fabric*additive Least Squares Means\n\n                                                Standard\nfabric  additive  _fabric  _additive  Estimate     Error     DF  t Value  Pr &gt; |t|   Alpha\n\nC       X         C        Y           10.5000    2.2407     12     4.69    0.0005    0.05\nC       X         P        X           -6.7500    2.2407     12    -3.01    0.0108    0.05\nC       X         P        Y           10.2500    2.2407     12     4.57    0.0006    0.05\nC       Y         P        X          -17.2500    2.2407     12    -7.70    &lt;.0001    0.05\nC       Y         P        Y           -0.2500    2.2407     12    -0.11    0.9130    0.05\nP       X         P        Y           17.0000    2.2407     12     7.59    &lt;.0001    0.05\n\n                       Differences of fabric*additive Least Squares Means\n\nfabric  additive  _fabric  _additive     Lower       Upper\n\nC       X         C        Y            5.6179     15.3821\nC       X         P        X          -11.6321     -1.8679\nC       X         P        Y            5.3679     15.1321\nC       Y         P        X          -22.1321    -12.3679\nC       Y         P        Y           -5.1321      4.6321\nP       X         P        Y           12.1179     21.8821\n    \nLet’s look more closely at the SAS code to see where those coefficients are coming from. Specifically, we’ll look at estimate statements 1 and 2 in detail.\nThe value provided by the estimate statement is constructed based on the estimates of the effects in the model: the estimates of\n\n\n\nWe’ve used cell means (treatment combination means) to see where main, simple, and interaction effects come from, but they can also be expressed as a function of the model effects.\nFor the pajama example, the lsmeans in SAS are\n\n\n\n\nand the treatment effects model is\n\n\n\n\n\nestimate statement #1: main effect for Cotton fabric\n\n\n\n\n\n\n\n\n\n\n\nestimate statement #2: (simple) effect of fabric with Additive X\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhy does learning this matter, if we’re duplicating results from lsmeans statements?\n\n\n\n\n\nFor practice, try estimate statement #3: main effect for Additive X\n\n\n\n\n\n\n\n\n\n\n\n\nFor practice, try estimate statement #4: (simple) effect of additive with Polyester fabric",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Factorial Treatment Designs</span>"
    ]
  },
  {
    "objectID": "Section 3 Factorial Treatment Design.html#more-than-two-levels-per-treatment-factor",
    "href": "Section 3 Factorial Treatment Design.html#more-than-two-levels-per-treatment-factor",
    "title": "3  Factorial Treatment Designs",
    "section": "3.4 More Than Two Levels per Treatment Factor",
    "text": "3.4 More Than Two Levels per Treatment Factor\nIn the pajama example, we had two levels for each of our two factors. Fabric was either cotton or polyester, and Additive was either X or Y. Now we’ll consider a factorial with more than two levels for each factor.\nExample: An experiment was conducted to aid in developing a product that can be used as a substrate for making ribbons. The experiment was designed to investigate the effects of base polymer and additive on the tensile strength of the resulting ribbon. There are two factors of interest: (1) base polymer: mylar, nylon, and polyethylene and (2) additive: c1, c2, c3, c4, and c5. There are 3 \\(\\times\\) 5 treatment combinations, and the researchers plan to test each treatment combination 6 times, for a total of 90 observations. The data are in the ribbon.sas file.\nThe model is\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nand the ANOVA table is\n\n\n\n\n\n\n\n\nLet’s look at an interaction plot to see what’s going on. We can also get an interaction plot using the lsmeans statement!\n    proc glimmix data=ribbon;\n      class polymer add;\n      model strength=polymer add polymer*add;\n      lsmeans polymer*add/plots=meanplot(sliceby=polymer join);\n    run;\nWhich gives\n\n\n\nInteraction plot for the ribbon data\n\n\nSo it looks like we have interaction!\nWe’ll also formally test for interaction\n           Type III Tests of Fixed Effects\n                Num      Den\nEffect           DF       DF    F Value    Pr &gt; F\npolymer           2       75      24.25    &lt;.0001\nadd               4       75       0.14    0.9648\npolymer*add       8       75       2.38    0.0241\nThis verifies what we see in the plot.\nSo, we must look at simple effects and not main effects. We’ll use the same slice and slicediff statements we used with the pajama example:\n    proc glimmix data=ribbon;\n      class polymer add;\n      model strength=polymer add polymer*add;\n      lsmeans polymer*add/slice=polymer slice=add slicediff=(polymer add);\n    run;\nThis is going to produce a LOT of output. Let’s look at the output for slice=add and slicediff=add.\n           Tests of Effect Slices for\n         polymer*add Sliced By add\n            Num      Den\n    add      DF       DF    F Value    Pr &gt; F\n    c1        2       75       3.41    0.0383\n    c2        2       75       3.53    0.0341\n    c3        2       75       4.90    0.0100\n    c4        2       75      14.31    &lt;.0001\n    c5        2       75       7.63    0.0010\n    \n                  Simple Effect Comparisons of polymer*add Least Squares Means By add\n    Simple\n    Effect                                       Standard\n    Level     polymer    _polymer    Estimate       Error       DF    t Value    Pr &gt; |t|\n    add c1    mylar      nylon         6.6833      2.5593       75       2.61      0.0109\n    add c1    mylar      poly          3.3500      2.5593       75       1.31      0.1945\n    add c1    nylon      poly         -3.3333      2.5593       75      -1.30      0.1968\n    add c2    mylar      nylon         6.6167      2.5593       75       2.59      0.0117\n    add c2    mylar      poly          1.9333      2.5593       75       0.76      0.4524\n    add c2    nylon      poly         -4.6833      2.5593       75      -1.83      0.0712\n    add c3    mylar      nylon         7.6833      2.5593       75       3.00      0.0036\n    add c3    mylar      poly          5.8167      2.5593       75       2.27      0.0259\n    add c3    nylon      poly         -1.8667      2.5593       75      -0.73      0.4681\n    add c4    mylar      nylon        12.4667      2.5593       75       4.87      &lt;.0001\n    add c4    mylar      poly         11.1333      2.5593       75       4.35      &lt;.0001\n    add c4    nylon      poly         -1.3333      2.5593       75      -0.52      0.6039\n    add c5    mylar      nylon         3.1167      2.5593       75       1.22      0.2271\n    add c5    mylar      poly          9.7833      2.5593       75       3.82      0.0003\n    add c5    nylon      poly          6.6667      2.5593       75       2.60      0.0111\nThe p-values given are for the LSD mean comparisons. We’re doing a lot of comparisons!\nWe can try to adjust for multiplicity by using the Tukey adjustment:\nlsmeans polymer*add/slicediff=(polymer add) cl adjust=tukey;\n\n              Simple Effect Comparisons of polymer*add Least Squares Means By add\n                          Adjustment for Multiple Comparisons: Tukey\nSimple\nEffect                                   Standard\nLevel    polymer   _polymer   Estimate      Error      DF   t Value   Pr &gt; |t|    Adj P    Alpha\nadd c1   mylar     nylon        6.6833     2.5593      75      2.61     0.0109   0.0290     0.05\nadd c1   mylar     poly         3.3500     2.5593      75      1.31     0.1945   0.3947     0.05\nadd c1   nylon     poly        -3.3333     2.5593      75     -1.30     0.1968   0.3983     0.05\nadd c2   mylar     nylon        6.6167     2.5593      75      2.59     0.0117   0.0310     0.05\nadd c2   mylar     poly         1.9333     2.5593      75      0.76     0.4524   0.7313     0.05\nadd c2   nylon     poly        -4.6833     2.5593      75     -1.83     0.0712   0.1669     0.05\nadd c3   mylar     nylon        7.6833     2.5593      75      3.00     0.0036   0.0101     0.05\nadd c3   mylar     poly         5.8167     2.5593      75      2.27     0.0259   0.0659     0.05\nadd c3   nylon     poly        -1.8667     2.5593      75     -0.73     0.4681   0.7469     0.05\nadd c4   mylar     nylon       12.4667     2.5593      75      4.87     &lt;.0001   &lt;.0001     0.05\nadd c4   mylar     poly        11.1333     2.5593      75      4.35     &lt;.0001   0.0001     0.05\nadd c4   nylon     poly        -1.3333     2.5593      75     -0.52     0.6039   0.8614     0.05\nadd c5   mylar     nylon        3.1167     2.5593      75      1.22     0.2271   0.4465     0.05\nadd c5   mylar     poly         9.7833     2.5593      75      3.82     0.0003   0.0008     0.05\nadd c5   nylon     poly         6.6667     2.5593      75      2.60     0.0111   0.0295     0.05\n\n Simple Effect Comparisons of polymer*add Least Squares Means By add\n                 Adjustment for Multiple Comparisons: Tukey\nSimple\nEffect                                                     Adj         Adj\nLevel    polymer   _polymer      Lower       Upper       Lower       Upper\nadd c1   mylar     nylon        1.5849     11.7817      0.5637     12.8029\nadd c1   mylar     poly        -1.7484      8.4484     -2.7696      9.4696\nadd c1   nylon     poly        -8.4317      1.7651     -9.4529      2.7863\nadd c2   mylar     nylon        1.5183     11.7151      0.4971     12.7363\nadd c2   mylar     poly        -3.1651      7.0317     -4.1863      8.0529\nadd c2   nylon     poly        -9.7817      0.4151    -10.8029      1.4363\nadd c3   mylar     nylon        2.5849     12.7817      1.5637     13.8029\nadd c3   mylar     poly         0.7183     10.9151     -0.3029     11.9363\nadd c3   nylon     poly        -6.9651      3.2317     -7.9863      4.2529\nadd c4   mylar     nylon        7.3683     17.5651      6.3471     18.5863\nadd c4   mylar     poly         6.0349     16.2317      5.0137     17.2529\nadd c4   nylon     poly        -6.4317      3.7651     -7.4529      4.7863\nadd c5   mylar     nylon       -1.9817      8.2151     -3.0029      9.2363\nadd c5   mylar     poly         4.6849     14.8817      3.6637     15.9029\nadd c5   nylon     poly         1.5683     11.7651      0.5471     12.7863\nEven with the Tukey adjustment, we need to remember the total number of comparisons we’re doing far exceeds the df for treatment. This means\n\n\n\nA better way to try to keep the experiment-wise error rate reasonable is to look at only a small set of comparisons that are planned before carrying out the experiment. contrast and estimate statements (or lsmestimate) can be used to look at these pre-planned comparisons.\nPlanned Comparisons\nIn our example, we were not specific about the goals of the experiment, beyond considering these two factors. Typically, a researcher has more information about the specific questions of interest. Suppose nylon and polyethylene have been used by the company in the past, and they are interest in how mylar compares as a potentially new option. This leads to some specific hypotheses the company may want to test.\nSo, in general, the company may be interested in\n\n\n\n\n\n\nBut there are several ways to look at this comparison\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNot all of these will be appropriate comparisons! It depends on whether or not interaction is present. If there is interaction, we have to use simple effects or a compromise. If there is no interaction, then we can use the main effects.\nWhen we would use the compromise? When there are subsets of additives where the polymer does not interact with additive.\nWe’ll now see how to we can use estimate, contrast, and lsmestimate statements to determine which of the comparisons above are important. The estimate statement is constructed based on the estimates of the effects in the model. The lsmestimate statement is constructed based on the treatment lsmeans (the cell means).\nHere’s a three step procedure to construct the contrast and estimate statements:\n\nWrite the linear combination you want to test or estimate in terms of the cell means, \\(\\mu_{ij}\\)\nConvert means into model parameters\nGather like terms\n\nThis will give you the coefficients to use in the statements. We’re going to start with lsmestimate, because this is where it really gets to shine.\nBefore determining the linear combinations, we need to know what order SAS has the lsmeans–this will tell us the order in which they go in the statements. The order is determined by the order the factors appear in the class statment (not the model statement) and then in alphanumeric order within each factor.\nFor example:\n        class polymer add;\n        model strength=polymer|add;\n        model strength=add|polymer;\nwill put the factors and levels in the same order.\nWe have three polymers with 5 additives, so the order of the coefficients would be\n\n\n\n\n\n\nHowever, if we use\n        class add polymer;\n        model strength=polymer|add;\n        model strength=add|polymer;\nwe’d get a different order. Now, the order of the coefficients would be\n\n\n\n\n\nLet’s stick with class polymer add order. We want to find the coefficients that we need to compare mylar vs the average of nylon and polyethylene in additive 1.\nWe want to test\n\n\n\n\n\nwhich maps to coefficients\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMc1\nMc2\nMc3\nMc4\nMc5\nNc1\nNc2\nNc3\nNc4\nNc5\nPc1\nPc2\nPc3\nPc4\nPc5\n\n\n\n\n\n\nWe can now add the lsmestimate statement to our program\nlsmestimate polymer*add 'Mylar vs Nylon,Poly in Add c1' 1 0 0 0 0 -0.5 0 0 0 0 -0.5 0 0 0 0;\nlsmestimate polymer*add 'Mylar vs Nylon,Poly in Add c1' 2 0 0 0 0 -1 0 0 0 0 -1 0 0 0 0/divisor=2;\nWe could additional statements to look at this same comparison with the other additives. Note that I’m not looking at this comparison in Additive c5, because we already saw there is a difference between nylon and polyethylene in c5 so it doesn’t make sense to look at this.\n        proc glimmix data=ribbon;\n          class polymer add;\n          model strength=polymer|add;\n          lsmestimate polymer*add \n            'Mylar vs Nylon,Poly in Add c1' 2 0 0 0 0 -1 0 0 0 0 -1 0 0 0 0,\n            'Mylar vs Nylon,Poly in Add c2' 0 2 0 0 0 0 -1 0 0 0 0 -1 0 0 0,\n            'Mylar vs Nylon,Poly in Add c3' 0 0 2 0 0 0 0 -1 0 0 0 0 -1 0 0,\n            'Mylar vs Nylon,Poly in Add c4' 0 0 0 2 0 0 0 0 -1 0 0 0 0 -1 0/divisor=2;\n        run;\n                                         Least Squares Means Estimates\n        \n                                                         Standard\nEffect        Label                           Estimate      Error      DF   t Value   Pr &gt; |t|\n        \npolymer*add   Mylar vs Nylon,Poly in Add c1     5.0167     2.2164      75      2.26     0.0265\npolymer*add   Mylar vs Nylon,Poly in Add c2     4.2750     2.2164      75      1.93     0.0575\npolymer*add   Mylar vs Nylon,Poly in Add c3     6.7500     2.2164      75      3.05     0.0032\npolymer*add   Mylar vs Nylon,Poly in Add c4    11.8000     2.2164      75      5.32     &lt;.0001\nWe see the estimates differ for the different additives, indicating a potential interaction between Mylar vs (Nylon & Poly) and Additive. We can investigate this further by comparing the simple effects. But for this, we need to use estimate.\nAgain the difference between lsmestimate and estimate is\n\n\n\n\nUsing estimate, we’ll need to go through the 3 step method outlined above.\n\nState the comparison in terms of the cell means\n\n\n\n\n\n\n\nConvert cell means into treatment effects\n\n\n\n\n\n\n\n\nGather like terms\n\n\n\n\n\n\n\nSo, our estimate statement will only involve the polymer and polymer*additive estimates.\n    proc glimmix data=ribbon;\n      class polymer add;\n      model strength=polymer|add;\n      estimate 'Mylar vs Nylon,Poly in Add c1' \n        polymer 2 -1 -1 polymer*add 2 0 0 0 0 -1 0 0 0 0 -1 0 0 0 0/divisor=2;\n    run;\nwhich gives\n                                           Estimates\n    \n                                                 Standard\n    Label                            Estimate       Error       DF    t Value    Pr &gt; |t|\n    \n     Mylar vs Nylon,Poly in Add c1      5.0167      2.2164       75       2.26      0.0265\n    \n    \nWe could also look at all four comparisons at once like we did with lsmestimate and we could also add the adjust= option to control multiplicity.\n    proc glimmix data=ribbon;\n      class polymer add;\n      model strength=polymer|add;\n      estimate 'Mylar vs Nylon,Poly in Add c1' \n          polymer 2 -1 -1 polymer*add 2 0 0 0 0 -1 0 0 0 0 -1 0 0 0 0,\n       'Mylar vs Nylon,Poly in Add c2' \n          polymer 2 -1 -1 polymer*add 0 2 0 0 0 0 -1 0 0 0 0 -1 0 0 0,  \n       'Mylar vs Nylon,Poly in Add c3' \n          polymer 2 -1 -1 polymer*add 0 0 2 0 0 0 0 -1 0 0 0 0 -1 0 0,\n       'Mylar vs Nylon,Poly in Add c4' \n          polymer 2 -1 -1 polymer*add 0 0 0 2 0 0 0 0 -1 0 0 0 0 -1 0/divisor=2;\n    run;\nThese give us the same results we saw with lsmestimate! So why bother going through all of this mess if we could get them more easily with lsmestimate? So now that we know how to build the estimate statements we can do so to explore contrasts to see if there is significant interaction. We can see there is from the Type III tests, but interaction now has 8 df–there’s a lot more going on with interaction than there was in a 2 \\(\\times\\) 2 model, and we need to tease it apart. Right now, we’re specifically interested in whether there is interaction between the mylar vs nylon/poly comparison and additive.\nLet’s write out the null hypothesis for this interaction.\n\n\n\n\n\n\n\n\n\nRather than a single equation for interaction like we saw in the 2 \\(\\times\\) 2, we actually have a set of 4 equations. This is a\n\n\n\nHow can we come up with the 4 equations to see what goes in the contrast statement?\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe’ll do the same thing we did in the three step process–write the means in terms of their treatment effects and gather like terms. Let’s look at c1 vs c5:\n\n\n\n\n\nSo the main effects cancel out and the only term we need in our contrast statement is polymer*add. That would give us coefficients:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMc1\nMc2\nMc3\nMc4\nMc5\nNc1\nNc2\nNc3\nNc4\nNc5\nPc1\nPc2\nPc3\nPc4\nPc5\n\n\n\n\n\n\nand our contrast statement would look like this:\n    proc glimmix data=ribbon;\n      class polymer add;\n      model strength=polymer|add;\n      contrast 'Mylar vs Nylon,Poly by Add interaction'\n        polymer*add 1 0 0 0 -1  -0.5 0 0 0 0.5  -0.5 0 0 0 0.5, \n        polymer*add 0 1 0 0 -1  0 -0.5 0 0 0.5  0 -0.5 0 0 0.5,\n        polymer*add 0 0 1 0 -1  0 0 -0.5 0 0.5  0 0 -0.5 0 0.5,\n        polymer*add 0 0 0 1 -1  0 0 0 -0.5 0.5  0 0 0 -0.5 0.5;\n    run;\nwhich gives\n            Type III Tests of Fixed Effects\n    \n                    Num      Den\n    Effect           DF       DF    F Value    Pr &gt; F\n    \n    polymer           2       75      24.25    &lt;.0001\n    add               4       75       0.14    0.9648\n    polymer*add       8       75       2.38    0.0241\n    \n    \n                                Contrasts\n    \n                                               Num      Den\n    Label                                       DF       DF    F Value    Pr &gt; F\n    \n    Mylar vs Nylon,Poly by Add interaction       4       75       1.76    0.1450\n    \nSo it looks like there is potentially interaction between this comparison of polymers and additive. If we wanted to present results for this comparison, we should do it separately for the 5 additives. If the structure of the factors lends itself to specific comparisons, we could also tease apart that 4 df interaction test.\nSuppose we do have additional knowledge about the factor structures, and Additives c1 and c2 are similarly formulated as are Additives c3 and c4. We already know that polymers N and P are different in c5, so so we can’t report M versus (N/P) for c5. We can further tease apart c1, c2, c3, and c4 and potentially report some more general effects. We’ll consider (c1 and c2) and (c3 and c4), and break apart that 4 df interaction test into 4 separate 1 df tests.\n\nH\\(_0:\\) No interaction between M vs (N/P) and Additives (c1 and c2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nH\\(_0:\\) No interaction between M vs (N/P) and Additives (c3 and c4)\n\n\n\n\n\n\nAt this point, if we were reporting our results, we’d stop. We can report M vs (N/P) averaged over (c1 and c2), but must report M vs (N/P) separately for the other 3 additives. Where do the other 2 df live?\nLet’s suppose (this is not true), that both contrast 1 and 2 had been non-significant. We could then move on to:\n\nCould we combine (c1 and c2) and (c3 and c4)?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe remaining df is:\n\nM vs (N/P) \\(\\times\\) [(c1/c2/c3/c4) vs c5]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Factorial Treatment Designs</span>"
    ]
  },
  {
    "objectID": "Section 3 Factorial Treatment Design.html#multifactor-experiments",
    "href": "Section 3 Factorial Treatment Design.html#multifactor-experiments",
    "title": "3  Factorial Treatment Designs",
    "section": "3.5 Multifactor Experiments",
    "text": "3.5 Multifactor Experiments\nSo far, we’ve discussed factorial experiments with two factors, A and B, both of which have 2 or more levels, \\(a\\) and \\(b\\). We’ve referred to this as an \\(a \\times b\\) factorial treatment design. We’re still considering the completely randomized (CRD) experimental design. If we add a factor C (with \\(c\\) levels) to our \\(a \\times b\\) design, we have an \\(a \\times b \\times c\\) factorial design. If all three factors have \\(a\\) levels, we can alternatively describe this as an \\(a^3\\) factorial. The total number of treatments is \\(a \\times b \\times c\\).\nExample: The following experiment was actually carried out in an experimental design class at Arizona State University, and considered some of the many different ways to bake brownies. The purpose of the experiment was to determine how the pan material, brand of brownie mix, and the stirring method affect the scrumptiousness of brownies. The factors and levels were:\n\n\n\n\nFactor\nLevels\n\n\n\n\nA= Pan Material\nGlass, Aluminum\n\n\nB= Stirring Method\nSpoon, Mixer\n\n\nC= Brand of Mix\nExpensive, Cheap\n\n\n\n\nThis is a \\(2 \\times 2 \\times 2 = 2^3\\) experiment. There are 8 treatment combinations:\n\n\n\n\n\n\nFactors\n\n\n\n\n\nTreatment\nPan\nStirring\nMix\n\n\n1\nGlass\nSpoon\nExpensive\n\n\n2\nAluminum\nSpoon\nExpensive\n\n\n3\nGlass\nMixer\nExpensive\n\n\n4\nAluminum\nMixer\nExpensive\n\n\n5\nGlass\nSpoon\nCheap\n\n\n6\nAluminum\nSpoon\nCheap\n\n\n7\nGlass\nMixer\nCheap\n\n\n8\nAluminum\nMixer\nCheap\n\n\n\n\nThe response variable was scrumptiousness, a subjective measured derived from a questionnaire given to the subjects who sampled each batch of brownies. The questionnaire included questions related to taste, appearance, consistency, aroma, etc. Eight batches of each treatment combination were rated, for a total of \\(8 \\times 8 = 64\\) experimental units.\nBefore we look at the data, let’s consider how we must adapt our notation, model, and ANOVA table for an additional factor.\nFirst, consider the cell mean \\(\\mu_{ijk}\\)\n\n\n\nOur response now have 4 subscripts: \\(y_{ijkl}\\)\n\n\n\n\nThe treatment effects model is:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnd a sketch of the ANOVA table:\n\n\n\n\n\n\nIt gets a little more complicated to make a table of cell means\n\n\n\n\n\nStirring\nMethod\nStirring\nMethod\n\n\n\n\n\nSpoon\nSpoon\nMixer\nMixer\n\n\n\nPan\nMaterial\nPan\nMaterial\n\n\nMix Brand\nGlass\nAluminum\nGlass\nAluminum\n\n\nExpensive\n\\(\\mu_{111}\\)\n\\(\\mu_{211}\\)\n\\(\\mu_{121}\\)\n\\(\\mu_{221}\\)\n\n\nCheap\n\\(\\mu_{112}\\)\n\\(\\mu_{212}\\)\n\\(\\mu_{122}\\)\n\\(\\mu_{222}\\)\n\n\n\n\nThe data are in the file brownie.sas. Let’s put in the observed cell means\n\n\n\n\n\nStirring\nMethod\nStirring\nMethod\n\n\n\n\n\nSpoon\nSpoon\nMixer\nMixer\n\n\n\nPan\nMaterial\nPan\nMaterial\n\n\nMix Brand\nGlass\nAluminum\nGlass\nAluminum\n\n\nExpensive\n\n\n\n\n\n\n\n\n\n\n\n\n\nCheap\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can also think about main effect marginal means\n\n\n\n\n\n\n\n\n\n\n\nand treatment combination marginal means\n\n\n\n\n\n\n\n3.5.1 Simple Effects and Interaction in a Multifactor Experiment\nWe can again look at simple effects but this time, instead of looking at the effect of one factor with the other held constant, simple effects describe the effect of one factor with the other two (or more) held constant.\nExample: We can consider the simple effect of pan material, given stirring with a spoon and expensive mix:\n\n\n\n\n\nWe can use simple effects to determine if there is conditional interaction. Conditional interaction means\n\n\n\nThis is denoted as \\(A \\times B | C_k\\) or \\(A \\times B | C\\). Determining whether \\(A \\times B | C_k\\) is nonzero is the same as asking\n\n\n\n\n\n\nWe can also construct interaction plots to explore this. For the brownie example, suppose we are interested in the interaction between pan material and stirring method, given the cheap brand.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can also examine the conditional interaction between pan material and stirring method, given the expensive mix.\nThese two plots together can be examined to see if there is a three-way interaction present. Three-way interaction occurs when\n\n\n\n\nIn this case, it does not appear there is significant three-way interaction. What would three-way interaction look like?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.5.2 Analysis for Multifactor Experiments\nWe’ll now explore the analysis of a three-way factorial treatment design by looking first at the analysis of the brownie data, and then two additional example data sets with increasingly complex interactions among the three factors.\nThe basic steps in analyzing data arising from a three-factor design are:\n\nInclude all main effects, two-way, and three-way interaction terms in the model and test the three-way interaction.\nIf the three-way interaction term is not significant, test the two-way interactions. If the three-way interaction is significant, test the two-way interactions at each level of the third factor (conditional interactions).\nDepending on the results of (1) and (2),\n\nTest main effects (for those main effects free of any interaction)\nTest simple effects of one factor conditional on the second but free of the third (when there are two-way interactions, but no three-way)\nTest simple effects of one factor conditional on combinations of the other two (when there is three-way interaction)\n\n\nThis can be conducted using a two-stage approach in SAS.\nStage 1: Run the basic analysis including all main effects, two-way interactions, and three-way interaction to see what is significant.\n    proc glimmix;\n      class a b c;\n      model y=a|b|c; *or model y=a b c a*b a*c b*c a*b*c;\n    run;\nStage 2: Add needed two-way interaction and/or main effect contrasts, lsmeans, slice, and slicediff statements to test various hypotheses and estimate various differences, depending on which thee-way or two-way interactions are significant (and therefore which hypotheses are legitimate to test).\n\n3.5.2.1 Brownie Example\nStage 1: We’ll start using the basic program\n    proc glimmix data=brownies;\n      class pan stir mix;\n      model y=pan|stir|mix;\n    run;\nwhich gives\n              Type III Tests of Fixed Effects\n    \n                     Num      Den\n    Effect            DF       DF    F Value    Pr &gt; F\n    \n    pan                1       56      11.95    0.0010\n    stir               1       56       2.99    0.0894\n    pan*stir           1       56       0.01    0.9194\n    mix                1       56       0.01    0.9194\n    pan*mix            1       56       0.26    0.6132\n    stir*mix           1       56       0.17    0.6858\n    pan*stir*mix       1       56       0.04    0.8396\n\n\n\n\nStage 2: Based on the output above, we only need to further investigate the (main) effects of pan material and (potentially) stirring method. We can refit the model without the interactions and add an lsmeans statements\n    proc glimmix data=brownies;\n      class pan stir mix;\n      model y=pan stir mix;\n      lsmeans pan stir/diff;\n    run;\nwhich gives\n         Type III Tests of Fixed Effects\n              Num      Den\nEffect         DF       DF    F Value    Pr &gt; F\n\npan             1       60      12.70    0.0007\nstir            1       60       3.17    0.0798\nmix             1       60       0.01    0.9169\n\n\n                 pan Least Squares Means\n                        Standard\npan         Estimate       Error       DF    t Value    Pr &gt; |t|\naluminum     12.6250      0.4217       60      29.94      &lt;.0001\nglass        10.5000      0.4217       60      24.90      &lt;.0001\n\n                Differences of pan Least Squares Means\n                                    Standard\npan         _pan        Estimate       Error       DF    t Value    Pr &gt; |t|\naluminum    glass         2.1250      0.5963       60       3.56      0.0007\n\n                  stir Least Squares Means\n                     Standard\nstir     Estimate       Error       DF    t Value    Pr &gt; |t|\nmixer     12.0938      0.4217       60      28.68      &lt;.0001\nspoon     11.0313      0.4217       60      26.16      &lt;.0001\n\n             Differences of stir Least Squares Means\n                              Standard\nstir     _stir    Estimate       Error       DF    t Value    Pr &gt; |t|\nmixer    spoon      1.0625      0.5963       60       1.78      0.0798\n\n\n3.5.2.2 Data Set #2 Example\nThe data are in the file multifactor examples.sas.\nLet’s first explore the cell means and sketch the interaction plots.\n                          a*b*c Least Squares Means\n    \n                               Standard\n    a    b    c    Estimate       Error       DF    t Value    Pr &gt; |t|\n    \n    1    1    1      221.83      4.8769       16      45.49      &lt;.0001\n    1    1    2      243.50      4.8769       16      49.93      &lt;.0001\n    1    2    1      239.77      4.8769       16      49.16      &lt;.0001\n    1    2    2      247.73      4.8769       16      50.80      &lt;.0001\n    2    1    1      254.87      4.8769       16      52.26      &lt;.0001\n    2    1    2      270.40      4.8769       16      55.44      &lt;.0001\n    2    2    1      232.07      4.8769       16      47.58      &lt;.0001\n    2    2    2      245.67      4.8769       16      50.37      &lt;.0001\nLet’s plot B \\(\\times\\) C for each level of A.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStage 1: We’ll start with the basic program\n    proc glimmix data=example2;\n      class a b c;\n      model y=a|b|c;\n    run;\n\n               Fit Statistics\n    \n    Pearson Chi-Square / DF        71.35\n    \n    \n         Type III Tests of Fixed Effects\n                  Num      Den\n    Effect         DF       DF    F Value    Pr &gt; F\n    \n    a               1       16      13.23    0.0022\n    b               1       16       3.38    0.0846\n    a*b             1       16      25.53    0.0001\n    c               1       16      18.15    0.0006\n    a*c             1       16       0.00    0.9715\n    b*c             1       16       1.28    0.2738\n    a*b*c           1       16       0.73    0.4062\nBased on this, we can look at the main effects of C and the simple effects of A given B (averaged over C) and B given A (averaged over C).\nStage 2:\n    proc glimmix data=example2;\n      class a b c;\n      model y=a b a*b c;\n      lsmeans c/diff;\n      lsmeans a*b/slicediff=a slicediff=b;\n    run;\n                 Fit Statistics\n    Pearson Chi-Square / DF        67.65\n    \n            Type III Tests of Fixed Effects\n                  Num      Den\n    Effect         DF       DF    F Value    Pr &gt; F\n    a               1       19      13.95    0.0014\n    b               1       19       3.57    0.0743\n    a*b             1       19      26.93    &lt;.0001\n    c               1       19      19.14    0.0003\n    \n                c Least Squares Means\n                     Standard\n    c    Estimate       Error       DF    t Value    Pr &gt; |t|\n    1      237.13      2.3743       19      99.87      &lt;.0001\n    2      251.83      2.3743       19     106.06      &lt;.0001\n    \n           Differences of c Least Squares Means\n                           Standard\n    c    _c    Estimate       Error       DF    t Value    Pr &gt; |t|\n    1    2     -14.6917      3.3578       19      -4.38      0.0003\n    \n                   a*b Least Squares Means\n                          Standard\n    a    b    Estimate       Error       DF    t Value    Pr &gt; |t|\n    1    1      232.67      3.3578       19      69.29      &lt;.0001\n    1    2      243.75      3.3578       19      72.59      &lt;.0001\n    2    1      262.63      3.3578       19      78.22      &lt;.0001\n    2    2      238.87      3.3578       19      71.14      &lt;.0001\n    \n          Simple Effect Comparisons of a*b Least Squares Means By a\n    Simple\n    Effect                           Standard\n    Level     b    _b    Estimate       Error       DF    t Value    Pr &gt; |t|\n    a 1       1    2     -11.0833      4.7486       19      -2.33      0.0307\n    a 2       1    2      23.7667      4.7486       19       5.00      &lt;.0001\n    \n           Simple Effect Comparisons of a*b Least Squares Means By b\n    Simple\n    Effect                           Standard\n    Level     a    _a    Estimate       Error       DF    t Value    Pr &gt; |t|\n    b 1       1    2     -29.9667      4.7486       19      -6.31      &lt;.0001\n    b 2       1    2       4.8833      4.7486       19       1.03      0.3167\nWe can also construct interaction plots to visualize the interaction between A and B:\n    proc glimmix data=example2;\n      class a b c;\n      model y=a b a*b c;\n      lsmeans a*b/plots=meanplot(sliceby=b join);\n    run;\n\n\n\nInteraction plot for A x B, averaged over C\n\n\nLet’s verify that this really is averaging over C.\n\n\n\n\n\n\n3.5.2.3 Data Set #3 Example\nThe data are in the file multifactor examples.sas.\nLet’s first explore the cell means and sketch the interaction plots.\n                      a*b*c Least Squares Means\n                           Standard\na    b    c    Estimate       Error       DF    t Value    Pr &gt; |t|\n\n1    1    1      223.13      6.2094       16      35.93      &lt;.0001\n1    1    2      234.53      6.2094       16      37.77      &lt;.0001\n1    2    1      247.77      6.2094       16      39.90      &lt;.0001\n1    2    2      259.57      6.2094       16      41.80      &lt;.0001\n2    1    1      245.67      6.2094       16      39.56      &lt;.0001\n2    1    2      275.30      6.2094       16      44.34      &lt;.0001\n2    2    1      265.33      6.2094       16      42.73      &lt;.0001\n2    2    2      249.90      6.2094       16      40.25      &lt;.0001\nLet’s plot B \\(\\times\\) C for each level of A.\n\n\n\n\n\n\n\n\n\n\n\nStage 1: We’ll start with the basic program\n    proc glimmix data=example2;\n    class a b c;\n    model y=a|b|c;\n    run;\n\n                  Fit Statistics\n        Pearson Chi-Square / DF       115.67\n    \n    \n         Type III Tests of Fixed Effects\n                  Num      Den\n    Effect         DF       DF    F Value    Pr &gt; F\n    \n    a               1       16      16.43    0.0009\n    b               1       16       6.26    0.0236\n    a*b             1       16       9.95    0.0061\n    c               1       16       4.53    0.0491\n    a*c             1       16       0.26    0.6153\n    b*c             1       16       6.47    0.0217\n    a*b*c           1       16       6.70    0.0198\nSo our suspicion of three-way interaction is verified. Let’s explore this a bit more using plots. We’ve seen the B \\(\\times\\) C for each level of A. To illustrate how to use SAS to construct the interaction plots, let’s consider A \\(\\times\\) B for each level of C.\n    proc glimmix data=example3;\n      class a b c;\n      model y=a|b|c;\n      lsmeans a*b*c/plot=meanplot (sliceby=b plotby=c join);\n    run;\n\n\n\n\n\n\nInteraction plot for A x B at level C=1\n\n\n\n\n\nInteraction plot for A x B at level C=2.\n\n\nSo it looks like there is no interaction between A and B at C=1.\nStage 2: We can formally test the interaction between A and B at C=1, and proceed based on the results. We’ll use the same approach we did in the last section:\n\nWrite the linear combination you want to test or estimate in terms of the cell means, \\(\\mu_{ij}\\)\nConvert means into model parameters\nGather like terms\n\nIn this case, we’re interested in \\(\\mu_{111} - \\mu_{121} - \\mu_{211} + \\mu_{221}\\).\n\n\n\n\n\n\n\n\n\nThis leads to the contrast statement\n    contrast 'a*b at c=1' a*b 1 -1 -1 1 a*b*c 1 0 -1 0 -1 0 1 0;\n\n                       Contrasts\n                   Num      Den\n    Label           DF       DF    F Value    Pr &gt; F\n    \n    a*b at c=1       1       16       0.16    0.6945\nAs suspected, there is no A \\(\\times\\) B interaction at C=1. So, we can examine the ‘main’ effects of A and B at C=1.\n    proc glimmix data=example3;\n      class a b c;\n      model y=a|b|c;\n      lsmeans a*c/slicediff=c;\n      lsmeans b*c/slicediff=c;\n    run;\n\n                        a*c Least Squares Means\n                          Standard\n    a    c    Estimate       Error       DF    t Value    Pr &gt; |t|\n    \n    1    1      235.45      4.3907       16      53.62      &lt;.0001\n    1    2      247.05      4.3907       16      56.27      &lt;.0001\n    2    1      255.50      4.3907       16      58.19      &lt;.0001\n    2    2      262.60      4.3907       16      59.81      &lt;.0001\n    \n            Simple Effect Comparisons of a*c Least Squares Means By c   \n    Simple\n    Effect                           Standard\n    Level     a    _a    Estimate       Error       DF    t Value    Pr &gt; |t|\n    \n    c 1       1    2     -20.0500      6.2094       16      -3.23      0.0052\n    c 2       1    2     -15.5500      6.2094       16      -2.50      0.0235\n\n\n\n                       b*c Least Squares Means\n                          Standard\n    b    c    Estimate       Error       DF    t Value    Pr &gt; |t|\n    \n    1    1      234.40      4.3907       16      53.39      &lt;.0001\n    1    2      254.92      4.3907       16      58.06      &lt;.0001\n    2    1      256.55      4.3907       16      58.43      &lt;.0001\n    2    2      254.73      4.3907       16      58.02      &lt;.0001\n    \n             Simple Effect Comparisons of b*c Least Squares Means By c\n    Simple\n    Effect                           Standard\n    Level     b    _b    Estimate       Error       DF    t Value    Pr &gt; |t|\n    \n    c 1       1    2     -22.1500      6.2094       16      -3.57      0.0026\n    c 2       1    2       0.1833      6.2094       16       0.03      0.9768\nHowever, it does look like there is an interaction between A and B if C=2. We’ll check this formally. This time, we’re interested in \\(\\mu_{112} - \\mu_{122} - \\mu_{212} + \\mu_{222}\\).\nPractice: Find the coefficients necessary to test this contrast.\n\n\n\n\n\n\n\n\n                       Contrasts\n                   Num      Den\n    Label           DF       DF    F Value    Pr &gt; F\n    \n    a*b at c=2       1       16      16.49    0.0009\nSo, the A \\(\\times\\) B interaction is significant. So, we must look at simple effects.\n    lsmeans a*b*c/slicediff=b*c slicediff=a*c;\n\n                         a*b*c Least Squares Means  \n                               Standard\n    a    b    c    Estimate       Error       DF    t Value    Pr &gt; |t|\n    \n    1    1    1      223.13      6.2094       16      35.93      &lt;.0001\n    1    1    2      234.53      6.2094       16      37.77      &lt;.0001\n    1    2    1      247.77      6.2094       16      39.90      &lt;.0001\n    1    2    2      259.57      6.2094       16      41.80      &lt;.0001\n    2    1    1      245.67      6.2094       16      39.56      &lt;.0001\n    2    1    2      275.30      6.2094       16      44.34      &lt;.0001\n    2    2    1      265.33      6.2094       16      42.73      &lt;.0001\n    2    2    2      249.90      6.2094       16      40.25      &lt;.0001\n    \n    \n             Simple Effect Comparisons of a*b*c Least Squares Means By b*c\n    Simple\n    Effect                            Standard\n    Level      a    _a    Estimate       Error       DF    t Value    Pr &gt; |t|\n    \n    b*c 1 1    1    2     -22.5333      8.7815       16      -2.57      0.0207\n    b*c 1 2    1    2     -40.7667      8.7815       16      -4.64      0.0003\n    b*c 2 1    1    2     -17.5667      8.7815       16      -2.00      0.0627\n    b*c 2 2    1    2       9.6667      8.7815       16       1.10      0.2873\n\n             Simple Effect Comparisons of a*b*c Least Squares Means By a*c\n    \n    Simple\n    Effect                            Standard\n    Level      b    _b    Estimate       Error       DF    t Value    Pr &gt; |t|\n    \n    a*c 1 1    1    2     -24.6333      8.7815       16      -2.81      0.0127\n    a*c 1 2    1    2     -25.0333      8.7815       16      -2.85      0.0116\n    a*c 2 1    1    2     -19.6667      8.7815       16      -2.24      0.0397\n    a*c 2 2    1    2      25.4000      8.7815       16       2.89      0.0106\nSo, how would we write an overall summary of the results of Example 3? We explored:\n\n‘Main’ effects of A and B at C=1\nSimple effects of A and B at C=2",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Factorial Treatment Designs</span>"
    ]
  },
  {
    "objectID": "Section 4 Block Designs.html",
    "href": "Section 4 Block Designs.html",
    "title": "4  Block Designs",
    "section": "",
    "text": "4.1 The Randomized Complete Block Design\nAt this point in the course, we make a distinct change of focus. Up to now, we’ve concentrated on analyzing data coming from various treatment designs. We’ve considered multiple flavors of one-way designs (unstructured, control vs others, regression, other structure) and factorials (2 factors, 3 factors, could have more than 3). In all cases though, we’ve been using the same experimental design: the completely randomized design (CRD). Now, we change our focus to other experimental designs. The treatment designs will be those we’ve seen before, and we’ll continue to analyze treatment effects using methods we’ve already discussed.\nWith a shift to experimental designs, we’ll be considering\nThis also means\nWe’re going to start with the simplest experimental design (besides the CRD): the randomized complete block design (RCBD) and then move on to other block designs.\nConsider an experiment in which we are interested in comparing six different lab activities for teaching the central limit theorem. Based on a power analysis, we believe four replications per treatment is sufficient, and so we need a total of 24 lab teams. We’ve got two options:\nWhich do you pick? Why? What are pros and cons of each?\nSuppose you decide to use teams in different classes (or you don’t have a choice). How will you assign treatments to teams?\nSuppose we allocate treatments to teams completely at random (CRD), and by chance four out of six teams in one class are assigned to treatment 1. Would you be okay with this?\nOne of the main problems with the CRD is a possible ‘conditional’ bias. That is, treatment assignment is not balanced relative to any systematic variation/gradient. In this experiment, the gradient is\nWhen this happens, treatment effect is confounded with gradient. Is any effect we observe really due to treatment, or is it due to the effect of the class? The other problem with the CRD is variance inflation. Suppose there is a gradient among the experimental units, with response increasing as you go up a gradient:\nEven if all the same treatment is applied throughout, the variance among the experimental units (the residuals) will be composed of two quantities:\nThis means it will appear larger than it actually is. The most common solution to these problems of confounding and variance inflation is blocking.\nThe idea of blocking is:\nBlocking allows us to reconcile two somewhat opposing aims of experimental design.\nIn summary, the general idea of blocking is to organize experimental units into groups that are as uniform as possible. We want to\nBlocks usually represent naturally occurring differences not related to treatments. If we block ‘correctly’ then the design accounts for block variation, and allows us to pull it out and isolate the usual random error due to experimental units. If we block ‘incorrectly’ then we get a weaker experiment.\nHow Do We Block?\nThere are two basic steps in blocking an experiment:\nThe simplest block design is the randomized complete block design (RCBD). In this design\nIn the RCBD, we carry out the two steps referenced on the previous page as\nAgain, we carry out step 1 with the goal\nThe model for the RCBD helps point out some considerations for choosing blocks. The model (assuming a one-way treatment design) is:\nThe ANOVA table looks like\nExample: An experiment was carried out to evaluate the effect of elevated CO\\(_2\\) on rice grain yield. Four blocks of 2 rice paddies each (each block owned by a different farmer, who used different fertilizer regimes and management practices over the years) are available for the experiment. In each paddy there is a 12 m diameter circular plot. In one plot in each block there is a ring of tubing around the plot emitting CO\\(_2\\) at a rate of 300 ppm above ambient level. In the other plot, no CO\\(_2\\) is emitted. The grain yield is measured at 3 locations in each plot at the end of the season, and the response is the average of the 3 locations.\nWhat is the experimental unit here?\nWhat does the assumption of no block \\(\\times\\) treatment interaction mean in this example?\nWe can check it with an interaction plot. Here are the means for each plot\nIf you had been presented with this data in STAT 102 (or STAT 318), how would you have analyzed it?",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Block Designs</span>"
    ]
  },
  {
    "objectID": "Section 4 Block Designs.html#the-randomized-complete-block-design",
    "href": "Section 4 Block Designs.html#the-randomized-complete-block-design",
    "title": "4  Block Designs",
    "section": "",
    "text": "Divide the experimental units into blocks of homogeneous units.\nRandomly assign treatments to units within blocks, using a separate randomization for each block. Every treatment will appear in every block.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBlock\nAmbient CO\\(_2\\)\nElevated CO\\(_2\\)\n\n\n\n\n1\n6.21\n6.41\n\n\n2\n6.25\n6.42\n\n\n3\n6.10\n6.26\n\n\n4\n6.14\n6.30\n\n\n\n\n\n\n\nInteraction plot for treatment x block.\n\n\n\n\n\n\n\n\nBlock\nAmbient CO\\(_2\\)\nElevated CO\\(_2\\)\n\n\n\n\n\n1\n6.21\n6.41\n\n\n\n2\n6.25\n6.42\n\n\n\n3\n6.10\n6.26\n\n\n\n4\n6.14\n6.30\n\n\n\n\n\n\n\n4.1.1 Selecting Blocks\nRemember that the RCBD is an experimental design, not a treatment design. It can be used with any treatment design. So, we might see RCBD layouts that look like:\n\n\n\n\nBlock 1\nBlock 2\nBlock 3\n\n\n\n\nControl\nTrt2\nTrt4\n\n\nTrt2\nControl\nTrt3\n\n\nTrt3\nTrt4\nTrt2\n\n\nTrt4\nTrt3\nControl\n\n\n\n\n\n\n\n\nBlock 1\nBlock 2\nBlock 3\n\n\n\n\n20\n60\n80\n\n\n60\n40\n20\n\n\n80\n80\n40\n\n\n40\n20\n60\n\n\n\n\n\n\n\n\nBlock 1\nBlock 2\nBlock 3\n\n\n\n\nA1 & B1\nA1 & B1\nA2 & B2\n\n\nA2 & B1\nA2 & B1\nA1 & B1\n\n\nA2 & B2\nA1 & B2\nA1 & B2\n\n\nA1 & B2\nA2 & B2\nA2 & B2\n\n\n\n\nWhen you write a report, both the treatment design and the experimental design need to be described in the methods section.\nTips for Choosing Blocks:\n\nWe want to maximize differences between blocks and minimize differences within blocks\n\n\n\n\n\n\n\n\nBlock size should not be excessively large\n\n\n\n\n\n\n\n\n\n\n\n\nKeep in the mind the no block \\(\\times\\) treatment interaction assumption\n\n\n\n\n\n\n\n\n\n\n\nCommon Criteria for Blocking:\n\ngradients that occur in the field, in greenhouses, in growth chambers\nweight groups in animal experimentation, litters, cage positions in a room\noccasion (day, month, year)\nlocation (barn, different fields, different rooms, different states)\nsubjects (each subject serves as their own control)\n\n\n\n4.1.2 RCBD Model and Analysis\nLet \\(y_{ij}\\) be\n\n\n\n\nEarlier we stated the model\n\n\n\n\n\n\n\n\nWe do have another choice to make. We can consider the block effect to either be a fixed effect or a random effect.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOur choice will have implications in the ANOVA table (in the Expected Mean Squares) and in the standard errors of the cell means.\n\n\n\n\nTo estimate the difference between two treatment means \\((\\mu_{i\\cdot} - \\mu_{i'\\cdot})\\), we use \\(\\overline y_{i\\cdot} - \\overline y_{i'\\cdot}\\). To figure out the variance (or estimate of the variance), let’s look at what \\(\\overline y_{i\\cdot}\\) is actually estimating:\n\n\n\n\n\n\n\n\n\n\nNow let’s explore the variance of this quantity.\n\n\n\n\n\n\n\n\n\nNow let’s consider \\(\\overline y_{i\\cdot} - \\overline y_{i'\\cdot}\\):\n\n\n\n\n\n\nand its variance\n\n\n\n\n\n\nIf we want to construct confidence intervals for treatment means or differences, they’ll have the form\n\n\n\nwhere the standard error is\nFor example, we use MSE as our estimate of \\(\\sigma^2\\), so confidence intervals for the difference between two means is\n\n\n\n\n\nRCBDs in SAS\nWe can still use PROC GLIMMIX to fit the model if our experimental design is the RCBD. The basic program for fixed blocks is\n    proc glimmix data=dataset;\n      class block trt;\n      model y = block trt;\n    run;\nNote:\n\n\n\nThe basic program for random blocks is\n    proc glimmix data=dataset;\n      class block trt;\n      model y = trt;\n      random block;\n    run;\nNote:\n\n\n\nExample: This experiment is looking at the emergence rate of soybean seeds treated with four different chemical treatments and a control.\n\n\n\n\nTreatment Number\nTreatment Name\n\n\n\n\n1\nControl\n\n\n2\nArasan\n\n\n3\nSpergon\n\n\n4\nSemesan\n\n\n5\nFermate\n\n\n\n\nExperimental Layout: The field is located on a slope, and blocks are formed based on elevation. There are five plots at each elevation, and five blocks.\n\n\n\n\n\n\n\n\n\n\n\n\n\nTreatment Design:\n\n\n\n\n100 seeds were planted in each plot, and the response is the number of plants that emerge out of the 100.\n\n\n\nModel:\n\n\n\n\n\n\nAnalysis with Blocks Fixed:\nIf we assume blocks are fixed, we use the code\nproc glimmix data=seeds;\n  class block chem;\n  model emerge=block chem;\nrun;\nwhich gives\n                 Fit Statistics\n    \n    Pearson Chi-Square / DF         5.41\n    \n         Type III Tests of Fixed Effects\n                  Num      Den\n    Effect         DF       DF    F Value    Pr &gt; F\n    \n    block           4       16       2.30    0.1032\n    chem            4       16       3.87    0.0219\n    \nThe follow-up analyses don’t change from what we’ve done so far. In this case, the treatment design is one-way treatment-versus-control, so comparing all treatments to the control is appropriate and we can use the Dunnett adjustment.\n    lsmeans chem/diff=control('Control') adjust=dunnett;\n\n                        Chem Least Squares Means\n    \n                           Standard\n    Chem       Estimate       Error       DF    t Value    Pr &gt; |t|\n    \n    Arasan      93.8000      1.0402       16      90.18      &lt;.0001\n    Control     89.2000      1.0402       16      85.75      &lt;.0001\n    Fermate     94.2000      1.0402       16      90.56      &lt;.0001\n    Semesan     93.4000      1.0402       16      89.79      &lt;.0001\n    Spergon     91.8000      1.0402       16      88.25      &lt;.0001\n                Differences of Chem Least Squares Means\n              Adjustment for Multiple Comparisons: Dunnett\n    \n                                      Standard\n    Chem       _Chem      Estimate       Error       DF    t Value    Pr &gt; |t|     Adj P\n    \n    Arasan     Control      4.6000      1.4711       16       3.13      0.0065    0.0218\n    Fermate    Control      5.0000      1.4711       16       3.40      0.0037    0.0125\n    Semesan    Control      4.2000      1.4711       16       2.86      0.0115    0.0375\n    Spergon    Control      2.6000      1.4711       16       1.77      0.0962    0.2680\n    \nAnalysis with Blocks Random:\nIf we assume blocks are random, we use the code\n    proc glimmix data=seeds;\n      class block chem;\n      model emerge=chem;\n      random block;\n      lsmeans chem/diff=control('Control') adjust=dunnett;\n    run;\nwhich gives\n              Fit Statistics\n    Gener. Chi-Square / DF          5.41\n    \n      Covariance Parameter Estimates\n                            Standard\n    Cov Parm    Estimate       Error\n    block         1.4100      1.8032\n    Residual      5.4100      1.9127\n    \n           Type III Tests of Fixed Effects\n                  Num      Den\n    Effect         DF       DF    F Value    Pr &gt; F\n    Chem            4       16       3.87    0.0219\n    \n                    Chem Least Squares Means\n                           Standard\n    Chem       Estimate       Error       DF    t Value    Pr &gt; |t| \n    Arasan      93.8000      1.1679       16      80.31      &lt;.0001\n    Control     89.2000      1.1679       16      76.38      &lt;.0001\n    Fermate     94.2000      1.1679       16      80.66      &lt;.0001\n    Semesan     93.4000      1.1679       16      79.97      &lt;.0001\n    Spergon     91.8000      1.1679       16      78.60      &lt;.0001\n                     Differences of Chem Least Squares Means\n                Adjustment for Multiple Comparisons: Dunnett-Hsu\n                                      Standard\n    Chem       _Chem      Estimate       Error       DF    t Value    Pr &gt; |t|     Adj P    \n    Arasan     Control      4.6000      1.4711       16       3.13      0.0065    0.0218\n    Fermate    Control      5.0000      1.4711       16       3.40      0.0037    0.0125\n    Semesan    Control      4.2000      1.4711       16       2.86      0.0115    0.0375\n    Spergon    Control      2.6000      1.4711       16       1.77      0.0962    0.2680\n    \nThe results are the same whether we used fixed blocks or random blocks. This is because our data are balanced–we had the same number of observations in each block, and all treatments appear in all blocks. If our data had not been balanced, the results would be different.\nLet’s go back to the ANOVA table to see where the estimate of \\(\\sigma^2_R\\) is coming from\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe just said that the analysis based on the treatment design will not change. Let’s consider an example with a one-way regression/quantitative factor levels treatment design.\nExample: In this experiment, seven soil samples were taken from the Canary Islands. Each soil sample was split into five subsamples and a phosphate (Na\\(_2\\),PO\\(_4\\)H) was added in amounts 0, 50, 100, 150, 200 ppm to these five subsamples (note even spacing). At the end of the experiment, the amount of exchangeable calcium was measured on each subsample. The seven samples serve as blocks. There are five levels of phosphate so\n\n\nLet’s first consider blocks fixed (it doesn’t matter here, since the experiment is balanced). First we have to decide the order of the polynomial:\n    proc glimmix data=soil;\n      class block;\n      model calcium=block phos phos*phos phos*phos*phos phos*phos*phos*phos/htype=1;\n    run;\nwhich gives output:\n                 Fit Statistics\n    Pearson Chi-Square / DF         0.13\n    \n                 Type I Tests of Fixed Effects\n                            Num      Den\n    Effect                   DF       DF    F Value    Pr &gt; F\n    \n    block                     6       24     109.80    &lt;.0001\n    phos                      1       24       7.08    0.0137\n    phos*phos                 1       24       1.62    0.2147\n    phos*phos*phos            1       24       1.88    0.1829\n    phos*phos*phos*phos       1       24       0.48    0.4940\n    \n\n\n\nNow that we’ve determined the appropriate polynomial, we can get the fitted model:\n    proc glimmix data=soil;\n      class block;\n      model calcium=block phos/htype=1 solution;\n    run;\nwhich gives\n                               Parameter Estimates\n                                      Standard\n    Effect       block    Estimate       Error       DF    t Value    Pr &gt; |t|\n    \n    Intercept               1.9737      0.1854       27      10.65      &lt;.0001\n    block        1          1.4520      0.2312       27       6.28      &lt;.0001\n    block        2          2.2280      0.2312       27       9.64      &lt;.0001\n    block        3          0.8540      0.2312       27       3.69      0.0010\n    block        4          0.4420      0.2312       27       1.91      0.0666\n    block        5          5.0280      0.2312       27      21.75      &lt;.0001\n    block        6          0.9960      0.2312       27       4.31      0.0002\n    block        7               0           .        .        .         .\n    phos                  0.002283    0.000874       27       2.61      0.0145\n    Scale                   0.1336     0.03637        .        .         .\n    \nSo the fitted model is:\n\n\n\n\n\n\nDo we really care about the effect Block 1 has on exchangeable calcium? Probably not. The seven soil samples were likely selected at random, so it really makes sense to treat blocks as random. Let’s go back to the most complicated possible model and start over.\n    proc glimmix data=soil;\n      class block;\n      model calcium=phos phos*phos phos*phos*phos phos*phos*phos*phos/htype=1;\n      random block;\n    run;\n\n      Covariance Parameter Estimates\n                            Standard\n    Cov Parm    Estimate       Error\n    \n    block         2.8049      1.6343\n    Residual      0.1289     0.03721\n    \n                 Type I Tests of Fixed Effects\n                            Num      Den\n    Effect                   DF       DF    F Value    Pr &gt; F\n    \n    phos                      1       24       7.08    0.0137\n    phos*phos                 1       24       1.62    0.2147\n    phos*phos*phos            1       24       1.88    0.1829\n    phos*phos*phos*phos       1       24       0.48    0.4940\n    \n\n\n\nNow let’s get the final model\n    proc glimmix data=soil;\n      class block;\n      model calcium=phos/htype=1 solution;\n      random block;\n    run;\n\n     Covariance Parameter Estimates\n                            Standard\n    Cov Parm    Estimate       Error\n    \n    block         2.8040      1.6343\n    Residual      0.1336     0.03637\n    \n                      Solutions for Fixed Effects\n                             Standard\n    Effect       Estimate       Error       DF    t Value    Pr &gt; |t|\n    \n    Intercept      3.5451      0.6419        6       5.52      0.0015\n    phos         0.002283    0.000874       27       2.61      0.0145\n    \n            Type I Tests of Fixed Effects\n                  Num      Den\n    Effect         DF       DF    F Value    Pr &gt; F\n    \n    phos            1       27       6.83    0.0145\n    \nSo, our fitted model is\n\n\n\nNote that when we treated blocks as either fixed or random\n\nWe ended up picking the same model\nThe estimate for the slope was the same\n\nOur goal was to describe the relationship between the treatment and the response. The blocks just give us a way to eliminate excess variance.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Block Designs</span>"
    ]
  },
  {
    "objectID": "Section 4 Block Designs.html#did-blocking-work",
    "href": "Section 4 Block Designs.html#did-blocking-work",
    "title": "4  Block Designs",
    "section": "4.2 Did Blocking Work?",
    "text": "4.2 Did Blocking Work?\nWhen we treated blocks as fixed effects, we get a p-value associated with block but it is completely meaningless because there is no valid hypothesis test for evaluating the effect of block. However, we can check the efficiency of the block design relative to a competing design.\nSuppose we have \\(t\\) treatments and \\(rt\\) experimental units available for our experiment. We have two possible experimental designs:\n\n\n\n\n\nThe only difference between these is whether we group the experimental units into blocks before randomly assigning the treatments. Efficiency gives us a way to compare the variance of two competing designs–we want to select the design that gives us the smaller variance of estimated treatment differences.\n\nCRD:\n\n\n\nRCBD\n\n\n\n\nSo the choice between these two designs comes down to a comparison of \\(\\sigma^2_{CRD}\\) and \\(\\sigma^2_{RCBD}\\). We can compare variances using a ratio called the relative efficiency.\n\n\nIf RE \\(&gt;\\) 1\n\n\n\n\n\n\n\n\nOnce we’ve conducted an RCBD experiment we can look and see whether we did the right thing when we used blocks.\n\n\n\n\n\nNote there is a difference in the error degrees of freedom between the CRD and RCBD which can have an impact. We can adjust for this difference by calculating the adjusted relative efficiency:\n\n\n\n\n\n\n\nThe correction factor is always less than 1, and usually won’t make much difference. It can make a difference if the number of treatments and reps is small.\nExample: Rice paddies In this example, there were 4 blocks and two treatments. We’ll fit the model both with blocks and without.\n\nRCBD:\n\n\n\n\nCRD:\n\n\n\nExample: Seed Emergence In this example, there were five blocks and five treatments. Again, we’ll fit the model both with blocks and without.\n\nRCBD:\n\nCRD:",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Block Designs</span>"
    ]
  },
  {
    "objectID": "Section 4 Block Designs.html#blocking-and-power",
    "href": "Section 4 Block Designs.html#blocking-and-power",
    "title": "4  Block Designs",
    "section": "4.3 Blocking and Power",
    "text": "4.3 Blocking and Power\nWe’ve used several methods to determine power and sample size for CRDs: proc power, proc glmpower, and tricking proc glimmix into calculating it for us. We can use the third option to incorporate blocking into our power calculations. These often require a pilot data set so we can get some idea about how much variance we expect among the blocks.\nExample: Researchers are interested in exploring the effect of three types of insecticide on the count of plant seedlings. They know there will be variability due to location in the greenhouse, so they plan on using an RCBD. They have pilot data from a previous study in the greenhouse, with 4 samples from 6 greenhouse benches selected at random. The data are in ‘block power.sas.’\nThe researchers want to treat block as random, so we need estimates of both \\(\\sigma^2\\) and \\(\\sigma^2_R\\). We can get estimates of both of these based on our pilot data, as well as 75% confidence intervals for the variances.\n\n\n\n\n\n\nWe can use the following code:\n    proc glimmix noprofile data=seedlings;\n      class plot;\n      model count = ;\n      random plot;\n      covtest / cl(type=plr alpha=0.25);\n    run;\n                              Covariance Parameter Estimates\n                                           Profile Likelihood 75% Confidence Bounds\n                                        ------- Lower ------    ------- Upper ------\n                            Standard                    Pr &gt;                    Pr &gt;\n    Cov Parm    Estimate       Error       Bound       Chisq       Bound       Chisq\n    \n    plot         44.5903     29.1831     22.5497      0.2500      104.00      0.2500\n    Residual      6.1806      2.0602      4.3102      0.2500      9.3093      0.2500\n    \nNow we’ve got estimates for the variances, and can turn our attention to the differences we want to be able to detect. The researchers are interested in detecting differences of 1, 2, and 3 units. We’re going to start with 6 blocks, and see if that’s enough power. They want \\(\\alpha=0.05\\) and are aiming for a power of 0.80.\nWe can modify the previous code we used to trick glimmix as follows:\n    *set up example data set with initial parameters;\n    data seedlingsa;\n      nblock=6;\n      input insecticide mu;\n      do block=1 to nblock;\n        output;\n      end;\n    datalines;\n    1 79\n    2 82\n    3 80\n    ;\n    \n    proc glimmix data=seedlingsa;\n      class block insecticide;\n      model mu=insecticide;\n      random block;\n      parms(104)(9.3093)/hold=1,2;\n      contrast '1 unit diff' insecticide 1 0 -1;\n      contrast '2 unit diff' insecticide 0 1 -1;\n      contrast '3 unit diff' insecticide 1 -1 0;\n      lsmeans  insecticide/diff cl;\n      ods output tests3=overallF1 contrasts=contrastF1;\n    run;\n    \n    /* Power computation & Print step */\n    data power1;\n      set overallF1 contrastF1;\n      alpha=0.05;\n      ncparm=numDF*Fvalue;\n      Critical_F=Finv(1-alpha,numDF,denDF,0);\n      Power=1-probF(Critical_F,numDF,denDF,ncparm);\n    \n    proc print data=power1;\n      var effect label numdf dendf alpha critical_F ncparm Power; \n      title 'power - RCBD';\n    run;\n    \nwhich gives the following:\n                                             power - RCBD        \n                              Num                      Critical_\n    Obs      Effect          Label         DF    DenDF    alpha        F         ncparm     Power\n    1     insecticide                      2       10     0.05     4.10282     3.00774    0.24820\n    2                    1 unit diff       1       10     0.05     4.96460     0.32226    0.08092\n    3                    2 unit diff       1       10     0.05     4.96460     1.28903    0.17731\n    4                    3 unit diff       1       10     0.05     4.96460     2.90033    0.33778\n    \nSo it doesn’t look like 6 blocks is enough. Even with a 3 unit difference, the power is only 0.33778. Let’s see what happens if we increase the block size to\n\n20 blocks:\n\n\n\n\n\n\n40 blocks:\n\n\n\n\n\n\n150 blocks:",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Block Designs</span>"
    ]
  },
  {
    "objectID": "Section 4 Block Designs.html#row-column-designs",
    "href": "Section 4 Block Designs.html#row-column-designs",
    "title": "4  Block Designs",
    "section": "4.4 Row-Column Designs",
    "text": "4.4 Row-Column Designs\nSometimes there are two blocking variables that can be used to reduce extraneous variability, rather than one factor. If it possible to block on both of the variables we may be able to increase precision while using the same number of experimental units as in a randomized complete block design.\nDesigns with two blocking criteria are called row-column designs. There are several different types of row-column designs,and we’ll discuss one of them, specifically the Latin square.\n\n\nRow-column designs tend to be situations in which there are two gradients:\n\n\n\n\n\n\n\n\n\nThe generic model for row-column designs is\n            observation = row + column + treatment + error\nWe assume there is no row\\(\\times\\)column interaction, no row\\(\\times\\)treatment interaction, and no column\\(\\times\\)treatment interaction.\nExample: Suppose we want to compare five kinds of glue, and glue is affected by temperature and humidity. Temperature and humidity vary across days and over time throughout the day, so two possible blocking criteria are day and hour. A Latin Square for five treatments blocks on day and hour looks like this\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEach day has a full set of five treatments and each hour has a full set of five treatments, so both day and hour could be considered blocks. The two types of blocking are superimposed on each other.\nThe Latin Square design requires\n\n\n\n\nBy using a Latin square arrangement, we are able to control for 5 rows \\(\\times\\) 5 columns \\(\\times\\) 5 treatments = 125 combinations using only 25 experimental units. Because of this feature, Latin squares have the potential for large gains in efficiency without using more experimental material.\nThe model for a Latin square is\n\n\n\n\n\n\n\n\n\nJust like with RCBDs we can consider rows and columns to be either fixed or random. The corresponding ANOVA table is\n\n\n\n\n\n\n\n\n\n\nExample: Consider an experiment to study yield of four wheat varieties (A, B, C, D). There are gradients running parallel to both sides of the field\n\n\n\n\n\nTo account for both gradients, the experiment was conducted as a 4 \\(\\times\\) 4 Latin square. Yields are in kg per plot. The plot layout with the data:\n\n\n\n\n\n\nColumn\n\n\n\n\nRow\n1\n2\n3\n4\n\n\n1\n10.5 (C)\n7.7 (D)\n12.0 (B)\n13.2 (A)\n\n\n2\n11.1 (B)\n12.0 (A)\n10.3 (C)\n7.5 (D)\n\n\n3\n5.8 (D)\n12.2 (C)\n11.2 (A)\n13.7 (B)\n\n\n4\n11.6 (A)\n12.3 (B)\n5.9 (D)\n10.2 (C)\n\n\n\n\nIn this example, the model is\n\n\n\n\n\n\n\n\n\n\n\nand ANOVA table\n\n\n\n\n\n\n\n\n\n\n\nThe analysis in SAS is very similar to the RCBD:\n  proc glimmix data=wheat;\n    class row col variety;\n    model yield=variety;\n    random row col;\n  run;\nIn this example, we are considering rows and columns as random effects. The output is:\n\n          Covariance Parameter Estimates\n                                Standard\n        Cov Parm    Estimate       Error\n        \n        row          0.04958      0.1482\n        col           0.4533      0.4673\n        Residual      0.4533      0.2617\n        \n               Type III Tests of Fixed Effects\n                      Num      Den\n        Effect         DF       DF    F Value    Pr &gt; F\n        \n        variety         3        6      58.03    &lt;.0001\nIt looks like there is a difference among the four varieties. We could follow up with whatever treatment design analysis is most appropriate (LSD, Tukey, maybe contrasts) just as before. A Latin square is a experimental design and like the RCBD can be paired with any treatment design.\nThe downside to the Latin square is that it can be restrictive, since # treatments = # columns = # rows. This means\n\n\n\n\n\n\n\n\n\n\n\n\nThe randomization of Latin squares is quite involved, and details will be left to a more advanced design course. There are other row-column designs as well which offer more flexibility than the Latin square. These include Latin rectangles and replicated Latin squares. We’ll also leave those to a second design course.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Block Designs</span>"
    ]
  },
  {
    "objectID": "Section 4 Block Designs.html#incomplete-block-designs",
    "href": "Section 4 Block Designs.html#incomplete-block-designs",
    "title": "4  Block Designs",
    "section": "4.5 Incomplete Block Designs",
    "text": "4.5 Incomplete Block Designs\nWhen we discussed RCBDs, we noted that we needed enough experimental units in each block to accommodate all treatments. However, in some situations, the number of treatments exceeds block size. This can happen because of the physical size of the block or shortages of experimental equipment or facilities. In instances like this, we can use randomized block designs in which every treatment is not present in every block. These designs are called incomplete block designs.\nExample: A baker is testing different cookie recipes, and has 9 recipes to test. Due to oven size and baking time available, the baker can only test 6 recipes per day. However, they know it’s important to block on day since oven temperature can vary day to to day. The RCDB would say use blocks of 1.5 days, and ignore the fact that days might not be homogeneous within a block. A better way is to use incomplete blocks of size six (one day). Consider the following set up:\n\n\n\n\n\nTreatments\n\n\n\n\nDay 1\n4, 5, 6, 7, 8, 9\n\n\n2\n2, 3, 5, 6, 8, 9\n\n\n3\n2, 3, 4, 6, 7, 8\n\n\n4\n2, 3, 4, 5, 7, 9\n\n\n5\n1, 3, 5, 6, 7, 8\n\n\n6\n1, 3, 4, 6, 7, 9\n\n\n7\n1, 3, 4, 5, 8, 9\n\n\n8\n1, 2, 5, 6, 8, 9\n\n\n9\n1, 2, 4, 6, 8, 9\n\n\n10\n1, 2, 4, 5, 7, 8\n\n\n11\n1, 2, 3, 7, 8, 9\n\n\n12\n1, 2, 3, 4, 5, 6\n\n\n\n\nThis design is a balanced incomplete block (BIB) design. It’s balanced because\n\n\n\n\nStandard notation for incomplete blocks is\n\n\n\n\n\n\n\n\n\n\n\nThese values are not independent, but must satisfy three conditions:\n\n\n\n\n\n\n\n\n\nAdditionally,\n\n\n\nBIBs do not exist for all combinations of blocks sizes, number of treatments, and number of replications. For example, with the cookie scenario, there is no BIB design with few than 8 replications. These restrictions means BIBs are not always feasible. However, when they are an option, they can very useful.\nExample: Suppose we have \\(t=6\\) treatments and block size that can accommodate \\(k=4\\) observations per block.\n\n\n\n\n\n\n\n\n\n\n\nSo if BIBs are not always feasible, why are they still useful? BIB designs are optimal in that\n\n\n\n\nIf you are willing to give up balance, we can find a design with far fewer replicates that is nearly balanced and nearly as efficient as a BIB would be if it existed. Partially balanced incomplete block (PBIB) designs share many features with BIBs. In PBIBs\n\n\n\nNot all incomplete block designs qualify as partially balanced. A PBIB must satisfy three criteria:\n\n\n\n\n\n\n\n\n\nConsider the following set-up:\n\n\n\n\n\nBlock\n\n\n\n\n\n1\n2\n3\n\n\n1\n2\n3\n\n\n4\n5\n6\n\n\n2\n3\n1\n\n\n5\n6\n4\n\n\n\n\n\n\nThe analysis of incomplete block designs is just like the analysis for an RCBD with missing data. We didn’t discuss the implications of missing data on the RCBD, but missing data means that we don’t get the same results for random and fixed blocks and we have to carefully think about which choice is most appropriate. Missing data also means that cell (arithmetic) means won’t be the same as lsmeans, and we should be sure to look at lsmeans.\nExample: An experiment was designed to test the wearing quality of \\(t=7\\) types of cloth. The machine used to test the wearing quality can only process four pieces of cloth at the same time. Machine run is considered the block. Here’s a layout of the design\n\n\n\n\n\n\n\nCloth\nType\n\n\n\n\n\nBlock\nA\nB\nC\nD\nE\nF\nG\n\n\n1\n\n627\n\n248\n\n563\n252\n\n\n2\n344\n\n233\n\n\n442\n226\n\n\n3\n\n\n251\n211\n160\n\n297\n\n\n4\n337\n537\n\n\n195\n\n300\n\n\n5\n\n520\n278\n\n199\n595\n\n\n\n6\n369\n\n\n196\n1985\n606\n\n\n\n7\n396\n602\n240\n273\n\n\n\n\n\n\n\nLet’s check that this is a BIB design.\nThe data are in fabric.sas. The model is\n\n\n\n\n\n\nand the ANOVA table is\n\n\n\n\n\n\n\n\n\nWe can use the same code we did with RCBDs:\n    proc glimmix data=fabric;\n      class block type;\n      model y=type;\n      random block;\n      lsmeans type/pdiff adjust=tukey;\n    run;\nIt seems like the 7 machine runs we used could be thought of as a random sample of all runs we could ever do on the machine, so I’m treating blocks as random. The output is\n      Covariance Parameter Estimates\n                            Standard\n    Cov Parm    Estimate       Error\n    \n    block         273.40      428.98\n    Residual     1471.43      537.29\n    \n            Type III Tests of Fixed Effects\n                  Num      Den\n    Effect         DF       DF    F Value    Pr &gt; F\n    \n    type            6       15      62.73    &lt;.0001\n    \n                     type Least Squares Means\n                        Standard\n    type    Estimate       Error       DF    t Value    Pr &gt; |t|\n    \n    A         363.84     20.6074       15      17.66      &lt;.0001\n    B         566.49     20.6074       15      27.49      &lt;.0001\n    C         252.61     20.6074       15      12.26      &lt;.0001\n    D         227.19     20.6074       15      11.02      &lt;.0001\n    E         184.03     20.6074       15       8.93      &lt;.0001\n    F         553.22     20.6074       15      26.85      &lt;.0001\n    G         273.13     20.6074       15      13.25      &lt;.0001\n    \n     \n                  Differences of type Least Squares Means\n              Adjustment for Multiple Comparisons: Tukey-Kramer\n                                 Standard\n    type    _type    Estimate       Error       DF    t Value    Pr &gt; |t|     Adj P\n    \n    A       B         -202.65     27.8771       15      -7.27      &lt;.0001    &lt;.0001\n    A       C          111.23     27.8771       15       3.99      0.0012    0.0160\n    A       D          136.65     27.8771       15       4.90      0.0002    0.0029\n    A       E          179.80     27.8771       15       6.45      &lt;.0001    0.0002\n    A       F         -189.38     27.8771       15      -6.79      &lt;.0001    &lt;.0001\n    A       G         90.7093     27.8771       15       3.25      0.0053    0.0630\n    B       C          313.88     27.8771       15      11.26      &lt;.0001    &lt;.0001\n    B       D          339.30     27.8771       15      12.17      &lt;.0001    &lt;.0001\n    B       E          382.46     27.8771       15      13.72      &lt;.0001    &lt;.0001\n    B       F         13.2728     27.8771       15       0.48      0.6408    0.9988\n    B       G          293.36     27.8771       15      10.52      &lt;.0001    &lt;.0001\n    C       D         25.4242     27.8771       15       0.91      0.3762    0.9648\n    C       E         68.5788     27.8771       15       2.46      0.0265    0.2407\n    C       F         -300.61     27.8771       15     -10.78      &lt;.0001    &lt;.0001\n    C       G        -20.5159     27.8771       15      -0.74      0.4731    0.9878\n    D       E         43.1546     27.8771       15       1.55      0.1425    0.7142\n    D       F         -326.03     27.8771       15     -11.70      &lt;.0001    &lt;.0001\n    D       G        -45.9401     27.8771       15      -1.65      0.1201    0.6566\n    E       F         -369.18     27.8771       15     -13.24      &lt;.0001    &lt;.0001\n    E       G        -89.0946     27.8771       15      -3.20      0.0060    0.0700\n    F       G          280.09     27.8771       15      10.05      &lt;.0001    &lt;.0001",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Block Designs</span>"
    ]
  },
  {
    "objectID": "Section 5 Split Plot Designs.html",
    "href": "Section 5 Split Plot Designs.html",
    "title": "5  Split-Plot Designs",
    "section": "",
    "text": "5.1 Model and Analysis of Variance\nSuppose we are carrying out an experiment to explore the effect of cold storage conditions on food quality. There are two treatment factors: storage temperature (2, 4, 8 degrees C) and container type (sealed plastic, open plastic, glass, and aluminum foil). A food product will be placed in one of the containers and stored in a small temperature controlled freezer for fixed period of time. There are 12 small freezers available for the experiment. Each freezer can hold 4 containers.\nWhat kind of treatment design is this?\nHow many treatment combinations are there?\nWhat is the experimental unit?\nWhat’s the problem?\nOne thing we can try is randomly assign storage temperatures to the freezers and randomly assign food products to storage containers within each freezer. The storage temperature is applied to all food samples in a freezer.\nExperimental unit for storage temperature:\nThe storage container is randomized separately, so the experimental unit for storage container:\nSo, we have two different sizes of experimental units for the two different factors in the experiment. Designs in which there are two sizes of experimental unit are called split-plot designs.\nSplit-plot designs are frequently used for factorial experiments, and may use CRD, RCBD, row-column, or incomplete block designs. The underlying principle of split-plots is\nThis means each whole unit becomes a block for the subunit treatments.\nConsider the following design structure. We have Factor A (four levels) laid out in 3 randomized complete blocks.\nA second Factor B (2 levels), can be superimposed by dividing each A unit into two subunits and assigning the two B treatment levels to these subunits.\nHere the A units are the whole units and the B units are the subunits.\nNote the randomization happens in two stages.\nEach whole plot may be considered as a block for Factor B, but it is not a complete block for the full set of treatments.\nWhy might we use split-plot designs?\nBig picture summary: variation among split-plot units is expected to be less than variation among whole plot units. This implies\nAs mentioned earlier, we can use split-plots in combination with any experimental design.\nTo determine the appropriate model, we’ll start with the whole/main plot. Consider the following whole plot arrangement\nLet’s sketch the ANOVA table for this arrangement\nNow let’s look only at the subplot arrangement:\nAnd sketch its ANOVA table\nIn order to get the main/whole unit analysis, the “block” is partitioned. The error from the subplot analysis can also be partitioned as each component times B, so we can examine the A \\(\\times\\) B interaction. If we put these two analyses together, we get (for the CRD):\nIf the main/whole plot is laid out in randomized complete blocks, the ANOVA table looks like this:\nThe model for the split-plot design incorporates both the whole plot and the sub plot. Without blocks, the model is\nTests of hypothesis in the split-plot will be constructed differently than we’ve seen before. To see this, let’s review the ANOVA table (for the CRD) for a regular factorial:\nNow let’s compare this with the ANOVA table for the split-plot (still CRD) with the expected mean squares:\nThis leads to different \\(F\\) statistics.\nFor testing the null hypothesis H\\(_0: \\alpha_1 = \\alpha_2 = \\cdots = \\alpha_a = 0\\)\nFor testing the null hypothesis H\\(_0: \\beta_1 = \\beta_2 = \\cdots = \\beta_b = 0\\)\nFor testing the null hypothesis H\\(_0: (\\alpha\\beta)_{11} = \\cdots = (\\alpha\\beta)_{ab} = 0\\)\nUsing these split units tends to mean",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Split-Plot Designs</span>"
    ]
  },
  {
    "objectID": "Section 5 Split Plot Designs.html#model-and-analysis-of-variance",
    "href": "Section 5 Split Plot Designs.html#model-and-analysis-of-variance",
    "title": "5  Split-Plot Designs",
    "section": "",
    "text": "A1\nA2\nA1\nA1\nA2\nA2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nB1\nB2\nB2\nB1\nB2\nB1\n\n\nB2\nB1\nB1\nB2\nB1\nB2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTests of main plot effects\n\n\n\nTests of sub plot effects",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Split-Plot Designs</span>"
    ]
  },
  {
    "objectID": "Section 5 Split Plot Designs.html#analysis-in-sas",
    "href": "Section 5 Split Plot Designs.html#analysis-in-sas",
    "title": "5  Split-Plot Designs",
    "section": "5.2 Analysis in SAS",
    "text": "5.2 Analysis in SAS\nTo correctly analyze the data in SAS (or any software), we have to identify the model terms correctly. Consider the following (very small) example:\n\n\n\n\n\n\n\n\n\n\n\n\n\nReplication\n(sub\nunit\nlevel)\n\n\n\n1\n2\n3\n4\n5\n6\n\n\nA1 (R1, wp)\nA2 (R1, wp)\nA1 (R2, wp)\nA1 (R3, wp)\nA2 (R2,wp)\nA2 (R3, wp)\n\n\nB2 (5.22)\nB1 (6.52)\nB1 (6.13)\nB1 (5.77)\nB2 (5.81)\nB2 (5.49)\n\n\nB1 (5.61)\nB2 (5.78)\nB2 (6.14)\nB2 (6.23)\nB1 (6.43)\nB1 (4.60)\n\n\n\n\nWhat can we tell about the experiment by looking at this layout?\n\n\n\nWe’ll need to identify the whole plot experimental unit for SAS. Let’s first use proc mixed, just so we can see the expected mean squares and make sure we’ve correctly identified the whole plot experimental unit.\n    proc mixed method=type3;\n      class rep A B;\n      model y=A B A*B;\n      random rep(A);\n    run;\n\n\n\nSAS output from PROC MIXED for the analysis of a split-plot\n\n\nSo the \\(F\\) value for Factor A is \\(F=2.98\\). This comes from\n\n\n\n\nFor the A \\(\\times\\) B interaction, the \\(F\\) value is \\(F=0.40\\). This comes from\n\n\nExample: A researcher is studying the absorption times of a particular type of antibiotic capsule. There are three dosage strengths and 4 capsule wall thicknesses, so 12 total treatment combinations. The researcher has decided on four replicates and it is necessary to run each replicate on a different day, so the researcher plans to block on day. On each day, each dosage strength is formulated. Once a particular dosage strength is formulated, all four wall thicknesses are tested at that strength. Then another dosage strength is selected, and all four wall thicknesses are tested. Finally, the third dosage strength and the four wall thicknesses are tested.\nThe experimental layout looks like this (everything would be appropriately randomized):\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDay 1\n\n\nDay 2\n\n\nDay 3\n\n\n\n\n\nDose1\nDose2\nDose3\nDose1\nDose2\nDose3\nDose1\nDose2\nDose3\n\n\nWall1\nWall1\nWall1\nWall1\nWall1\nWall1\nWall1\nWall1\nWall1\n\n\nWall2\nWall2\nWall2\nWall2\nWall2\nWall2\nWall2\nWall2\nWall2\n\n\nWall3\nWall3\nWall3\nWall3\nWall3\nWall3\nWall3\nWall3\nWall3\n\n\nWall4\nWall4\nWall4\nWall4\nWall4\nWall4\nWall4\nWall4\nWall4\n\n\n\n\n\nBlock:\n\nMain plot treatment factor:\n\nMain plot experimental unit:\n\nSubplot treatment factor:\n\nSubplot experimental unit:\n\n\nSo, we’ll put\n\n\nin the random statement to identify main plot error.\nAgain, we’ll use proc mixed, just so we can see the expected mean squares and make sure we’ve correctly identified the whole plot experimental unit.\nproc mixed data=antibiotic method=type3;\n  class day dosage wall;\n  model time=day dosage wall dosage*wall;\n  random day*dosage;\nrun;\n\n\n\nPROC MIXED analysis of the antibiotic capsule data\n\n\nSo the \\(F\\) value for dosage strength is \\(F=315.92\\). This comes from\n\n\n\n\nFor the wall thickness effect, the \\(F\\) value is \\(F=48.94\\). This comes from\n\n\n\nWe could also consider day as a random effect. We’ll go back to proc glimmix, since we no longer need the expected mean squares:\n    proc glimmix data=antibiotic;\n      class day dosage wall;\n      model time=dosage wall dosage*wall;\n      random day day*dosage;\n    run;\nHere’s part of the output\n  Estimated G matrix is not positive definite.\n    \n      Covariance Parameter Estimates\n                              Standard\n    Cov Parm      Estimate       Error\n    \n    day                  0           .\n    day*dosage      0.2454      1.1182\n    Residual        7.4699      2.0330\n    \n           Type III Tests of Fixed Effects\n                    Num      Den\n    Effect           DF       DF    F Value    Pr &gt; F\n    \n    dosage            2        6     462.06    &lt;.0001\n    wall              3       27      48.94    &lt;.0001\n    dosage*wall       6       27       4.38    0.0033\n    \nThese don’t match what we had with fixed days, and weird things are happening! What do you notice?\n\n\n\n\n\n\nLet’s try something else\n    proc glimmix data=antibiotic nobound;\n      class day dosage wall;\n      model time=dosage wall dosage*wall;\n      random day day*dosage;\n    run;\n\n   Estimated G matrix is not positive definite.\n    \n         Covariance Parameter Estimates\n                              Standard\n    Cov Parm      Estimate       Error\n    \n    day            -0.9774      0.5963\n    day*dosage      1.2228      1.8552\n    Residual        7.4699      2.0331\n    \n            Type III Tests of Fixed Effects\n                    Num      Den\n    Effect           DF       DF    F Value    Pr &gt; F\n    \n    dosage            2        6     315.92    &lt;.0001\n    wall              3       27      48.94    &lt;.0001\n    dosage*wall       6       27       4.38    0.0033\nWhat do you notice now?\n\n\n\n\n\nLet’s treat blocks as fixed, just for the sake of demonstrating how we should be estimating treatment means and differences in a split-plot experiment.\nThe model with blocks:\n\n\n\n\n\n\n\nThe main plot treatment mean is \\(\\mu_{i\\cdot}\\), and the natural estimator is \\(\\overline y_{i\\cdot \\cdot} = \\frac{1}{rb}\\sum_{k=1}^b \\sum_{j=1}^r y_{ijk}\\). For the antibiotic data with dosage strength 1, we get\n\\[\\begin{eqnarray*}\n    \\overline y_{i\\cdot \\cdot} &=& \\frac{1}{(4)(4)} [ (95 + 104 + 101 + 108) + (95 + 106 + 103 + 109) \\\\\n    & & + (96 + 105 + 106 + 113) + (90 + 100 + 102 + 114) ] \\\\\n    &=& \\frac{1}{16} (408 + 413 + 420 + 406) = 102.9375\\\\\n\\end{eqnarray*}\\]\nThe hardest part is obtaining the estimate of the variance of the mean. First, keep in mind\n\n\n\n\n\n\nTo figure out the variance of \\(\\overline y_{i\\cdot \\cdot}\\), let’s think about what it’s actually estimating (assuming balanced data and fixed blocks):\n\\[\\overline y_{i\\cdot \\cdot} = \\frac{1}{rb}\\sum_{k=1}^b \\sum_{j=1}^r y_{ijk} =  \\frac{1}{rb}\\sum_{k=1}^b \\sum_{j=1}^r (\\mu_{ij} + R_j + w_{ij} + e_{ijk})\\] So,\n\n\n\n\n\n\n\nLet’s check this in SAS\n                          Standard\n    dosage    Estimate       Error       DF    t Value    Pr &gt; |t|\n    \n    1           102.94      0.8790        6     117.11      &lt;.0001\nWhat about differences between two whole plot treatment means? We estimate \\(\\mu_{i\\cdot} - \\mu_{i'\\cdot}\\) with \\(\\overline y_{i\\cdot \\cdot} - \\overline y_{i'\\cdot \\cdot}\\), and estimate the variance of the difference with\n\n\n\n\n\n\n\n\n\nChecking in SAS:\n                    Differences of dosage Least Squares Means\n                                     Standard\n    dosage    _dosage    Estimate       Error       DF    t Value    Pr &gt; |t|\n    \n    1         2           21.1250      1.2430        6      16.99      &lt;.0001\n    1         3           -9.3750      1.2430        6      -7.54      0.0003\n    2         3          -30.5000      1.2430        6     -24.54      &lt;.0001\nEstimating the variance of the difference between simple effects gets even more complicated, so we’ll just let SAS do it. But, we do need to be aware that depending on the form of the standard error, the default degrees of freedom calculated by SAS may or may not be correct. Any time the standard error cannot be estimated by a single mean square (for many simple effects), the degrees of freedom must be estimated. We can do this by asking SAS to use the Kenward-Roger approximation to the degrees of freedom.\n    proc glimmix data=antibiotic;\n      class day dosage wall;\n      model time=day dosage wall dosage*wall/ddfm=kr;\n      random day*dosage;\n      lsmeans dosage/pdiff;\n      lsmeans dosage*wall/pdiff;\n    run;\nThis gives (in part)\n                     Differences of dosage Least Squares Means\n                                     Standard\n    dosage    _dosage    Estimate       Error       DF    t Value    Pr &gt; |t|\n    1         2           21.1250      1.2430        6      16.99      &lt;.0001\n    1         3           -9.3750      1.2430        6      -7.54      0.0003\n    2         3          -30.5000      1.2430        6     -24.54      &lt;.0001\n    \n                    dosage*wall Least Squares Means\n                              Standard\ndosage    wall    Estimate       Error       DF    t Value    Pr &gt; |t|\n1         1        94.0000      1.4742    27.44      63.76      &lt;.0001\n1         2         103.75      1.4742    27.44      70.38      &lt;.0001\n1         3         103.00      1.4742    27.44      69.87      &lt;.0001\n1         4         111.00      1.4742    27.44      75.30      &lt;.0001\n2         1        71.7500      1.4742    27.44      48.67      &lt;.0001\n2         2        82.7500      1.4742    27.44      56.13      &lt;.0001\n2         3        86.0000      1.4742    27.44      58.34      &lt;.0001\n2         4        86.7500      1.4742    27.44      58.85      &lt;.0001\n3         1         108.50      1.4742    27.44      73.60      &lt;.0001\n3         2         110.50      1.4742    27.44      74.96      &lt;.0001\n3         3         115.00      1.4742    27.44      78.01      &lt;.0001\n3         4         115.25      1.4742    27.44      78.18      &lt;.0001\n                      \n                        Differences of dosage*wall Least Squares Means\n                                                  Standard\ndosage    wall    _dosage    _wall    Estimate       Error       DF    t Value    Pr &gt; |t|\n1         1       1          2         -9.7500      1.9326       27      -5.05      &lt;.0001\n1         1       1          3         -9.0000      1.9326       27      -4.66      &lt;.0001\n1         1       1          4        -17.0000      1.9326       27      -8.80      &lt;.0001\n1         1       2          1         22.2500      2.0848    27.44      10.67      &lt;.0001\n1         1       2          2         11.2500      2.0848    27.44       5.40      &lt;.0001\n1         1       2          3          8.0000      2.0848    27.44       3.84      0.0007\n1         1       2          4          7.2500      2.0848    27.44       3.48      0.0017\n1         1       3          1        -14.5000      2.0848    27.44      -6.96      &lt;.0001\n1         1       3          2        -16.5000      2.0848    27.44      -7.91      &lt;.0001\n1         1       3          3        -21.0000      2.0848    27.44     -10.07      &lt;.0001\n1         1       3          4        -21.2500      2.0848    27.44     -10.19      &lt;.0001\n1         2       1          3          0.7500      1.9326       27       0.39      0.7010\n1         2       1          4         -7.2500      1.9326       27      -3.75      0.0009\n1         2       2          1         32.0000      2.0848    27.44      15.35      &lt;.0001\n1         2       2          2         21.0000      2.0848    27.44      10.07      &lt;.0001\n1         2       2          3         17.7500      2.0848    27.44       8.51      &lt;.0001\n1         2       2          4         17.0000      2.0848    27.44       8.15      &lt;.0001\n1         2       3          1         -4.7500      2.0848    27.44      -2.28      0.0307\n1         2       3          2         -6.7500      2.0848    27.44      -3.24      0.0031",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Split-Plot Designs</span>"
    ]
  },
  {
    "objectID": "Section 5 Split Plot Designs.html#more-complicated-split-plot-designs",
    "href": "Section 5 Split Plot Designs.html#more-complicated-split-plot-designs",
    "title": "5  Split-Plot Designs",
    "section": "5.3 More Complicated Split-Plot Designs",
    "text": "5.3 More Complicated Split-Plot Designs\nThe concept of split-plot designs can be extended to\n\nSplit-split-plot designs (or more splits). Sub-plot units are themselves further divided into sub-sub-plot units.\n\n\n\n\n\n\n\n\n\n\n\n\n\nSplit block/Strip-split plot designs. These lead to 3 different experimental units: for A, B, and A \\(\\times\\) B.\n\n\n\n\n\n\n\n\n\n\n\n\nRepeated measures designs. One of the factors is time, and measurements are taken repeatedly on the same experimental unit.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Split-Plot Designs</span>"
    ]
  }
]